[2023-12-27 23:44:33,544] torch.distributed.run: [WARNING] 
[2023-12-27 23:44:33,544] torch.distributed.run: [WARNING] *****************************************
[2023-12-27 23:44:33,544] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2023-12-27 23:44:33,544] torch.distributed.run: [WARNING] *****************************************
[2023-12-27 23:44:35,646] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-12-27 23:44:35,646] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-12-27 23:44:35,646] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-12-27 23:44:35,646] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-12-27 23:44:35,647] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-12-27 23:44:35,647] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-12-27 23:44:35,647] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-12-27 23:44:35,647] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [92m[OKAY][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [92m[OKAY][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [92m[OKAY][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [92m[OKAY][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [92m[OKAY][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [92m[OKAY][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
async_io ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
async_io ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
ninja .................. [92m[OKAY][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
async_io ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
async_io ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [92m[OKAY][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
async_io ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
async_io ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
async_io ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
async_io ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/usr/local/lib/python3.8/dist-packages/torch']
torch version .................... 2.1.0a0+gitda1ccca
deepspeed install path ........... ['/usr/local/lib/python3.8/dist-packages/deepspeed']
deepspeed info ................... 0.12.6, unknown, unknown
torch cuda version ............... 12.1
torch hip version ................ None
nvcc version ..................... 12.1
deepspeed wheel compiled w. ...... torch 2.1, cuda 12.1
shared memory (/dev/shm) size .... 503.52 GB
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/usr/local/lib/python3.8/dist-packages/torch']
torch version .................... 2.1.0a0+gitda1ccca
deepspeed install path ........... ['/usr/local/lib/python3.8/dist-packages/deepspeed']
deepspeed info ................... 0.12.6, unknown, unknown
torch cuda version ............... 12.1
torch hip version ................ None
nvcc version ..................... 12.1
deepspeed wheel compiled w. ...... torch 2.1, cuda 12.1
shared memory (/dev/shm) size .... 503.52 GB
DeepSpeed general environment info:
torch install path ............... ['/usr/local/lib/python3.8/dist-packages/torch']
torch version .................... 2.1.0a0+gitda1ccca
deepspeed install path ........... ['/usr/local/lib/python3.8/dist-packages/deepspeed']
deepspeed info ................... 0.12.6, unknown, unknown
torch cuda version ............... 12.1
torch hip version ................ None
nvcc version ..................... 12.1
deepspeed wheel compiled w. ...... torch 2.1, cuda 12.1
shared memory (/dev/shm) size .... 503.52 GB
DeepSpeed general environment info:
torch install path ............... ['/usr/local/lib/python3.8/dist-packages/torch']
torch version .................... 2.1.0a0+gitda1ccca
deepspeed install path ........... ['/usr/local/lib/python3.8/dist-packages/deepspeed']
deepspeed info ................... 0.12.6, unknown, unknown
torch cuda version ............... 12.1
torch hip version ................ None
nvcc version ..................... 12.1
deepspeed wheel compiled w. ...... torch 2.1, cuda 12.1
shared memory (/dev/shm) size .... 503.52 GB
DeepSpeed general environment info:
torch install path ............... ['/usr/local/lib/python3.8/dist-packages/torch']
torch version .................... 2.1.0a0+gitda1ccca
deepspeed install path ........... ['/usr/local/lib/python3.8/dist-packages/deepspeed']
deepspeed info ................... 0.12.6, unknown, unknown
torch cuda version ............... 12.1
torch hip version ................ None
nvcc version ..................... 12.1
deepspeed wheel compiled w. ...... torch 2.1, cuda 12.1
shared memory (/dev/shm) size .... 503.52 GB
DeepSpeed general environment info:
torch install path ............... ['/usr/local/lib/python3.8/dist-packages/torch']
torch version .................... 2.1.0a0+gitda1ccca
deepspeed install path ........... ['/usr/local/lib/python3.8/dist-packages/deepspeed']
deepspeed info ................... 0.12.6, unknown, unknown
torch cuda version ............... 12.1
torch hip version ................ None
nvcc version ..................... 12.1
deepspeed wheel compiled w. ...... torch 2.1, cuda 12.1
shared memory (/dev/shm) size .... 503.52 GB
DeepSpeed general environment info:
torch install path ............... ['/usr/local/lib/python3.8/dist-packages/torch']
torch version .................... 2.1.0a0+gitda1ccca
deepspeed install path ........... ['/usr/local/lib/python3.8/dist-packages/deepspeed']
deepspeed info ................... 0.12.6, unknown, unknown
torch cuda version ............... 12.1
torch hip version ................ None
nvcc version ..................... 12.1
deepspeed wheel compiled w. ...... torch 2.1, cuda 12.1
shared memory (/dev/shm) size .... 503.52 GB
DeepSpeed general environment info:
torch install path ............... ['/usr/local/lib/python3.8/dist-packages/torch']
torch version .................... 2.1.0a0+gitda1ccca
deepspeed install path ........... ['/usr/local/lib/python3.8/dist-packages/deepspeed']
deepspeed info ................... 0.12.6, unknown, unknown
torch cuda version ............... 12.1
torch hip version ................ None
nvcc version ..................... 12.1
deepspeed wheel compiled w. ...... torch 2.1, cuda 12.1
shared memory (/dev/shm) size .... 503.52 GB
**** Git info for Megatron: git_hash=71e8407c git_branch=main ****
**** Git info for Megatron: git_hash=71e8407c git_branch=main ****
What type of tokenizer to use.
What type of tokenizer to use.
********args.tokenizer_type:GPT2BPETokenizer*******
********args.tokenizer_type:GPT2BPETokenizer*******
**** Git info for Megatron: git_hash=71e8407c git_branch=main ****
What type of tokenizer to use.
********args.tokenizer_type:GPT2BPETokenizer*******
**** Git info for Megatron: git_hash=71e8407c git_branch=main ****
**** Git info for Megatron: git_hash=71e8407c git_branch=main ****
What type of tokenizer to use.
********args.tokenizer_type:GPT2BPETokenizer*******
What type of tokenizer to use.
********args.tokenizer_type:GPT2BPETokenizer*******
**** Git info for Megatron: git_hash=71e8407c git_branch=main ****
What type of tokenizer to use.
**** Git info for Megatron: git_hash=71e8407c git_branch=main ****
********args.tokenizer_type:GPT2BPETokenizer*******
What type of tokenizer to use.
********args.tokenizer_type:GPT2BPETokenizer*******
**** Git info for Megatron: git_hash=71e8407c git_branch=main ****
What type of tokenizer to use.
********args.tokenizer_type:GPT2BPETokenizer*******
[2023-12-27 23:44:49,196] [INFO] [comm.py:637:init_distributed] cdb=None
> setting tensorboard ...
[2023-12-27 23:45:04,345] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-12-27 23:45:04,363] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-12-27 23:45:04,393] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-12-27 23:45:04,424] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-12-27 23:45:05,711] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-12-27 23:45:05,727] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-12-27 23:45:05,779] [INFO] [comm.py:637:init_distributed] cdb=None
kml-dtmachine-13390-prod:34129:34129 [2] NCCL INFO cudaDriverVersion 12010
kml-dtmachine-13390-prod:34134:34134 [6] NCCL INFO cudaDriverVersion 12010
kml-dtmachine-13390-prod:34134:34134 [6] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34129:34129 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34134:34134 [6] NCCL INFO Bootstrap : Using eth0:11.40.80.237<0>
kml-dtmachine-13390-prod:34129:34129 [2] NCCL INFO Bootstrap : Using eth0:11.40.80.237<0>
kml-dtmachine-13390-prod:34134:34134 [6] NCCL INFO Plugin name set by env to libnccl-net-none.so
kml-dtmachine-13390-prod:34129:34129 [2] NCCL INFO Plugin name set by env to libnccl-net-none.so
kml-dtmachine-13390-prod:34134:34134 [6] NCCL INFO NET/Plugin : Plugin load (libnccl-net-none.so) returned 2 : libnccl-net-none.so: cannot open shared object file: No such file or directory
kml-dtmachine-13390-prod:34129:34129 [2] NCCL INFO NET/Plugin : Plugin load (libnccl-net-none.so) returned 2 : libnccl-net-none.so: cannot open shared object file: No such file or directory
kml-dtmachine-13390-prod:34134:34134 [6] NCCL INFO NET/Plugin : No plugin found, using internal implementation
kml-dtmachine-13390-prod:34129:34129 [2] NCCL INFO NET/Plugin : No plugin found, using internal implementation
kml-dtmachine-13390-prod:34136:34136 [7] NCCL INFO cudaDriverVersion 12010
kml-dtmachine-13390-prod:34136:34136 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34136:34136 [7] NCCL INFO Bootstrap : Using eth0:11.40.80.237<0>
kml-dtmachine-13390-prod:34136:34136 [7] NCCL INFO Plugin name set by env to libnccl-net-none.so
kml-dtmachine-13390-prod:34136:34136 [7] NCCL INFO NET/Plugin : Plugin load (libnccl-net-none.so) returned 2 : libnccl-net-none.so: cannot open shared object file: No such file or directory
kml-dtmachine-13390-prod:34136:34136 [7] NCCL INFO NET/Plugin : No plugin found, using internal implementation
kml-dtmachine-13390-prod:34130:34130 [3] NCCL INFO cudaDriverVersion 12010
kml-dtmachine-13390-prod:34131:34131 [4] NCCL INFO cudaDriverVersion 12010
kml-dtmachine-13390-prod:34127:34127 [0] NCCL INFO cudaDriverVersion 12010
kml-dtmachine-13390-prod:34131:34131 [4] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34130:34130 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34128:34128 [1] NCCL INFO cudaDriverVersion 12010
kml-dtmachine-13390-prod:34131:34131 [4] NCCL INFO Bootstrap : Using eth0:11.40.80.237<0>
kml-dtmachine-13390-prod:34130:34130 [3] NCCL INFO Bootstrap : Using eth0:11.40.80.237<0>
kml-dtmachine-13390-prod:34131:34131 [4] NCCL INFO Plugin name set by env to libnccl-net-none.so
kml-dtmachine-13390-prod:34130:34130 [3] NCCL INFO Plugin name set by env to libnccl-net-none.so
kml-dtmachine-13390-prod:34131:34131 [4] NCCL INFO NET/Plugin : Plugin load (libnccl-net-none.so) returned 2 : libnccl-net-none.so: cannot open shared object file: No such file or directory
kml-dtmachine-13390-prod:34131:34131 [4] NCCL INFO NET/Plugin : No plugin found, using internal implementation
kml-dtmachine-13390-prod:34130:34130 [3] NCCL INFO NET/Plugin : Plugin load (libnccl-net-none.so) returned 2 : libnccl-net-none.so: cannot open shared object file: No such file or directory
kml-dtmachine-13390-prod:34130:34130 [3] NCCL INFO NET/Plugin : No plugin found, using internal implementation
kml-dtmachine-13390-prod:34128:34128 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34128:34128 [1] NCCL INFO Bootstrap : Using eth0:11.40.80.237<0>
kml-dtmachine-13390-prod:34128:34128 [1] NCCL INFO Plugin name set by env to libnccl-net-none.so
kml-dtmachine-13390-prod:34128:34128 [1] NCCL INFO NET/Plugin : Plugin load (libnccl-net-none.so) returned 2 : libnccl-net-none.so: cannot open shared object file: No such file or directory
kml-dtmachine-13390-prod:34128:34128 [1] NCCL INFO NET/Plugin : No plugin found, using internal implementation
kml-dtmachine-13390-prod:34127:34127 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34127:34127 [0] NCCL INFO Bootstrap : Using eth0:11.40.80.237<0>
kml-dtmachine-13390-prod:34127:34127 [0] NCCL INFO Plugin name set by env to libnccl-net-none.so
kml-dtmachine-13390-prod:34127:34127 [0] NCCL INFO NET/Plugin : Plugin load (libnccl-net-none.so) returned 2 : libnccl-net-none.so: cannot open shared object file: No such file or directory
kml-dtmachine-13390-prod:34127:34127 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation
kml-dtmachine-13390-prod:34132:34132 [5] NCCL INFO cudaDriverVersion 12010
kml-dtmachine-13390-prod:34132:34132 [5] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34132:34132 [5] NCCL INFO Bootstrap : Using eth0:11.40.80.237<0>
kml-dtmachine-13390-prod:34132:34132 [5] NCCL INFO Plugin name set by env to libnccl-net-none.so
kml-dtmachine-13390-prod:34132:34132 [5] NCCL INFO NET/Plugin : Plugin load (libnccl-net-none.so) returned 2 : libnccl-net-none.so: cannot open shared object file: No such file or directory
kml-dtmachine-13390-prod:34132:34132 [5] NCCL INFO NET/Plugin : No plugin found, using internal implementation
kml-dtmachine-13390-prod:34134:34478 [6] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34134:34478 [6] NCCL INFO NCCL_IB_HCA set to mlx5_0

kml-dtmachine-13390-prod:34134:34478 [6] misc/ibvwrap.cc:94 NCCL WARN Call to ibv_open_device failed

kml-dtmachine-13390-prod:34134:34478 [6] transport/net_ib.cc:193 NCCL WARN NET/IB : Unable to open device mlx5_0

kml-dtmachine-13390-prod:34134:34478 [6] misc/ibvwrap.cc:94 NCCL WARN Call to ibv_open_device failed

kml-dtmachine-13390-prod:34134:34478 [6] transport/net_ib.cc:193 NCCL WARN NET/IB : Unable to open device mlx5_1
kml-dtmachine-13390-prod:34134:34478 [6] NCCL INFO NET/IB : No device found.
kml-dtmachine-13390-prod:34134:34478 [6] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34134:34478 [6] NCCL INFO NET/Socket : Using [0]eth0:11.40.80.237<0>
kml-dtmachine-13390-prod:34134:34478 [6] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34136:34479 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34136:34479 [7] NCCL INFO NCCL_IB_HCA set to mlx5_0

kml-dtmachine-13390-prod:34136:34479 [7] misc/ibvwrap.cc:94 NCCL WARN Call to ibv_open_device failed

kml-dtmachine-13390-prod:34136:34479 [7] transport/net_ib.cc:193 NCCL WARN NET/IB : Unable to open device mlx5_0

kml-dtmachine-13390-prod:34136:34479 [7] misc/ibvwrap.cc:94 NCCL WARN Call to ibv_open_device failed

kml-dtmachine-13390-prod:34136:34479 [7] transport/net_ib.cc:193 NCCL WARN NET/IB : Unable to open device mlx5_1
kml-dtmachine-13390-prod:34136:34479 [7] NCCL INFO NET/IB : No device found.
kml-dtmachine-13390-prod:34136:34479 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34136:34479 [7] NCCL INFO NET/Socket : Using [0]eth0:11.40.80.237<0>
kml-dtmachine-13390-prod:34136:34479 [7] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34129:34480 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34129:34480 [2] NCCL INFO NCCL_IB_HCA set to mlx5_0
kml-dtmachine-13390-prod:34130:34482 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34130:34482 [3] NCCL INFO NCCL_IB_HCA set to mlx5_0
kml-dtmachine-13390-prod:34131:34481 [4] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34131:34481 [4] NCCL INFO NCCL_IB_HCA set to mlx5_0
kml-dtmachine-13390-prod:34128:34483 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34128:34483 [1] NCCL INFO NCCL_IB_HCA set to mlx5_0
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO NCCL_IB_HCA set to mlx5_0

kml-dtmachine-13390-prod:34129:34480 [2] misc/ibvwrap.cc:94 NCCL WARN Call to ibv_open_device failed

kml-dtmachine-13390-prod:34129:34480 [2] transport/net_ib.cc:193 NCCL WARN NET/IB : Unable to open device mlx5_0

kml-dtmachine-13390-prod:34129:34480 [2] misc/ibvwrap.cc:94 NCCL WARN Call to ibv_open_device failed

kml-dtmachine-13390-prod:34129:34480 [2] transport/net_ib.cc:193 NCCL WARN NET/IB : Unable to open device mlx5_1
kml-dtmachine-13390-prod:34129:34480 [2] NCCL INFO NET/IB : No device found.
kml-dtmachine-13390-prod:34129:34480 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34129:34480 [2] NCCL INFO NET/Socket : Using [0]eth0:11.40.80.237<0>
kml-dtmachine-13390-prod:34129:34480 [2] NCCL INFO Using network Socket

kml-dtmachine-13390-prod:34130:34482 [3] misc/ibvwrap.cc:94 NCCL WARN Call to ibv_open_device failed

kml-dtmachine-13390-prod:34130:34482 [3] transport/net_ib.cc:193 NCCL WARN NET/IB : Unable to open device mlx5_0

kml-dtmachine-13390-prod:34130:34482 [3] misc/ibvwrap.cc:94 NCCL WARN Call to ibv_open_device failed

kml-dtmachine-13390-prod:34130:34482 [3] transport/net_ib.cc:193 NCCL WARN NET/IB : Unable to open device mlx5_1
kml-dtmachine-13390-prod:34130:34482 [3] NCCL INFO NET/IB : No device found.
kml-dtmachine-13390-prod:34130:34482 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34130:34482 [3] NCCL INFO NET/Socket : Using [0]eth0:11.40.80.237<0>
kml-dtmachine-13390-prod:34130:34482 [3] NCCL INFO Using network Socket

kml-dtmachine-13390-prod:34131:34481 [4] misc/ibvwrap.cc:94 NCCL WARN Call to ibv_open_device failed

kml-dtmachine-13390-prod:34131:34481 [4] transport/net_ib.cc:193 NCCL WARN NET/IB : Unable to open device mlx5_0

kml-dtmachine-13390-prod:34131:34481 [4] misc/ibvwrap.cc:94 NCCL WARN Call to ibv_open_device failed

kml-dtmachine-13390-prod:34131:34481 [4] transport/net_ib.cc:193 NCCL WARN NET/IB : Unable to open device mlx5_1
kml-dtmachine-13390-prod:34131:34481 [4] NCCL INFO NET/IB : No device found.
kml-dtmachine-13390-prod:34131:34481 [4] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34131:34481 [4] NCCL INFO NET/Socket : Using [0]eth0:11.40.80.237<0>
kml-dtmachine-13390-prod:34131:34481 [4] NCCL INFO Using network Socket

kml-dtmachine-13390-prod:34128:34483 [1] misc/ibvwrap.cc:94 NCCL WARN Call to ibv_open_device failed

kml-dtmachine-13390-prod:34128:34483 [1] transport/net_ib.cc:193 NCCL WARN NET/IB : Unable to open device mlx5_0

kml-dtmachine-13390-prod:34128:34483 [1] misc/ibvwrap.cc:94 NCCL WARN Call to ibv_open_device failed

kml-dtmachine-13390-prod:34128:34483 [1] transport/net_ib.cc:193 NCCL WARN NET/IB : Unable to open device mlx5_1
kml-dtmachine-13390-prod:34128:34483 [1] NCCL INFO NET/IB : No device found.
kml-dtmachine-13390-prod:34128:34483 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34128:34483 [1] NCCL INFO NET/Socket : Using [0]eth0:11.40.80.237<0>
kml-dtmachine-13390-prod:34128:34483 [1] NCCL INFO Using network Socket

kml-dtmachine-13390-prod:34127:34484 [0] misc/ibvwrap.cc:94 NCCL WARN Call to ibv_open_device failed

kml-dtmachine-13390-prod:34127:34484 [0] transport/net_ib.cc:193 NCCL WARN NET/IB : Unable to open device mlx5_0

kml-dtmachine-13390-prod:34127:34484 [0] misc/ibvwrap.cc:94 NCCL WARN Call to ibv_open_device failed

kml-dtmachine-13390-prod:34127:34484 [0] transport/net_ib.cc:193 NCCL WARN NET/IB : Unable to open device mlx5_1
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO NET/IB : No device found.
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO NET/Socket : Using [0]eth0:11.40.80.237<0>
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34132:34485 [5] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34132:34485 [5] NCCL INFO NCCL_IB_HCA set to mlx5_0

kml-dtmachine-13390-prod:34132:34485 [5] misc/ibvwrap.cc:94 NCCL WARN Call to ibv_open_device failed

kml-dtmachine-13390-prod:34132:34485 [5] transport/net_ib.cc:193 NCCL WARN NET/IB : Unable to open device mlx5_0

kml-dtmachine-13390-prod:34132:34485 [5] misc/ibvwrap.cc:94 NCCL WARN Call to ibv_open_device failed

kml-dtmachine-13390-prod:34132:34485 [5] transport/net_ib.cc:193 NCCL WARN NET/IB : Unable to open device mlx5_1
kml-dtmachine-13390-prod:34132:34485 [5] NCCL INFO NET/IB : No device found.
kml-dtmachine-13390-prod:34132:34485 [5] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
kml-dtmachine-13390-prod:34132:34485 [5] NCCL INFO NET/Socket : Using [0]eth0:11.40.80.237<0>
kml-dtmachine-13390-prod:34132:34485 [5] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34136:34479 [7] NCCL INFO comm 0x7a6f26a0 rank 15 nranks 16 cudaDev 7 nvmlDev 7 busId d6000 commId 0x403f453a942ea82e - Init START
kml-dtmachine-13390-prod:34134:34478 [6] NCCL INFO comm 0x797f79e0 rank 14 nranks 16 cudaDev 6 nvmlDev 6 busId d2000 commId 0x403f453a942ea82e - Init START
kml-dtmachine-13390-prod:34132:34485 [5] NCCL INFO comm 0x7b07d1d0 rank 13 nranks 16 cudaDev 5 nvmlDev 5 busId cf000 commId 0x403f453a942ea82e - Init START
kml-dtmachine-13390-prod:34131:34481 [4] NCCL INFO comm 0x797c3820 rank 12 nranks 16 cudaDev 4 nvmlDev 4 busId ce000 commId 0x403f453a942ea82e - Init START
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO comm 0x7b18d3f0 rank 8 nranks 16 cudaDev 0 nvmlDev 0 busId 35000 commId 0x403f453a942ea82e - Init START
kml-dtmachine-13390-prod:34130:34482 [3] NCCL INFO comm 0x7b148260 rank 11 nranks 16 cudaDev 3 nvmlDev 3 busId 3d000 commId 0x403f453a942ea82e - Init START
kml-dtmachine-13390-prod:34128:34483 [1] NCCL INFO comm 0x7b6d3b20 rank 9 nranks 16 cudaDev 1 nvmlDev 1 busId 36000 commId 0x403f453a942ea82e - Init START
kml-dtmachine-13390-prod:34129:34480 [2] NCCL INFO comm 0x7a894f60 rank 10 nranks 16 cudaDev 2 nvmlDev 2 busId 39000 commId 0x403f453a942ea82e - Init START
kml-dtmachine-13390-prod:34128:34483 [1] NCCL INFO Setting affinity for GPU 1 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34128:34483 [1] NCCL INFO NVLS multicast support is not available on dev 1
kml-dtmachine-13390-prod:34130:34482 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34130:34482 [3] NCCL INFO NVLS multicast support is not available on dev 3
kml-dtmachine-13390-prod:34129:34480 [2] NCCL INFO Setting affinity for GPU 2 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34129:34480 [2] NCCL INFO NVLS multicast support is not available on dev 2
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO Setting affinity for GPU 0 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34136:34479 [7] NCCL INFO Setting affinity for GPU 7 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34136:34479 [7] NCCL INFO NVLS multicast support is not available on dev 7
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO NVLS multicast support is not available on dev 0
kml-dtmachine-13390-prod:34131:34481 [4] NCCL INFO Setting affinity for GPU 4 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34131:34481 [4] NCCL INFO NVLS multicast support is not available on dev 4
kml-dtmachine-13390-prod:34132:34485 [5] NCCL INFO Setting affinity for GPU 5 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34134:34478 [6] NCCL INFO Setting affinity for GPU 6 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34134:34478 [6] NCCL INFO NVLS multicast support is not available on dev 6
kml-dtmachine-13390-prod:34132:34485 [5] NCCL INFO NVLS multicast support is not available on dev 5
kml-dtmachine-13390-prod:34136:34479 [7] NCCL INFO Trees [0] -1/-1/-1->15->14 [1] -1/-1/-1->15->14
kml-dtmachine-13390-prod:34136:34479 [7] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34134:34478 [6] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13
kml-dtmachine-13390-prod:34132:34485 [5] NCCL INFO Trees [0] 14/-1/-1->13->12 [1] 14/-1/-1->13->12
kml-dtmachine-13390-prod:34134:34478 [6] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34131:34481 [4] NCCL INFO Trees [0] 13/-1/-1->12->11 [1] 13/-1/-1->12->11
kml-dtmachine-13390-prod:34132:34485 [5] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34128:34483 [1] NCCL INFO Trees [0] 10/-1/-1->9->8 [1] 10/-1/-1->9->8
kml-dtmachine-13390-prod:34130:34482 [3] NCCL INFO Trees [0] 12/-1/-1->11->10 [1] 12/-1/-1->11->10
kml-dtmachine-13390-prod:34129:34480 [2] NCCL INFO Trees [0] 11/-1/-1->10->9 [1] 11/-1/-1->10->9
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO Trees [0] 9/-1/-1->8->0 [1] 9/0/-1->8->-1
kml-dtmachine-13390-prod:34131:34481 [4] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34128:34483 [1] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34130:34482 [3] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34129:34480 [2] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34127:34499 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 2.
kml-dtmachine-13390-prod:34127:34499 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 4.
kml-dtmachine-13390-prod:34127:34499 [0] NCCL INFO NET/Socket: Using 4 threads and 2 sockets per thread
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO Channel 00/0 : 7[7] -> 8[0] [receive] via NET/Socket/0
kml-dtmachine-13390-prod:34127:34499 [0] NCCL INFO NET/Socket: Using 4 threads and 2 sockets per thread
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO Channel 01/0 : 7[7] -> 8[0] [receive] via NET/Socket/0
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO Channel 00/0 : 8[0] -> 9[1] via P2P/IPC
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO Channel 01/0 : 8[0] -> 9[1] via P2P/IPC
kml-dtmachine-13390-prod:34131:34481 [4] NCCL INFO Channel 00/0 : 12[4] -> 13[5] via P2P/IPC
kml-dtmachine-13390-prod:34129:34480 [2] NCCL INFO Channel 00/0 : 10[2] -> 11[3] via P2P/IPC
kml-dtmachine-13390-prod:34132:34485 [5] NCCL INFO Channel 00/0 : 13[5] -> 14[6] via P2P/IPC
kml-dtmachine-13390-prod:34128:34483 [1] NCCL INFO Channel 00/0 : 9[1] -> 10[2] via P2P/IPC
kml-dtmachine-13390-prod:34134:34478 [6] NCCL INFO Channel 00/0 : 14[6] -> 15[7] via P2P/IPC
kml-dtmachine-13390-prod:34136:34479 [7] NCCL INFO Channel 00/0 : 15[7] -> 0[0] [send] via NET/Socket/0
kml-dtmachine-13390-prod:34136:34479 [7] NCCL INFO Channel 01/0 : 15[7] -> 0[0] [send] via NET/Socket/0
kml-dtmachine-13390-prod:34129:34480 [2] NCCL INFO Channel 01/0 : 10[2] -> 11[3] via P2P/IPC
kml-dtmachine-13390-prod:34128:34483 [1] NCCL INFO Channel 01/0 : 9[1] -> 10[2] via P2P/IPC
kml-dtmachine-13390-prod:34132:34485 [5] NCCL INFO Channel 01/0 : 13[5] -> 14[6] via P2P/IPC
kml-dtmachine-13390-prod:34134:34478 [6] NCCL INFO Channel 01/0 : 14[6] -> 15[7] via P2P/IPC
kml-dtmachine-13390-prod:34131:34481 [4] NCCL INFO Channel 01/0 : 12[4] -> 13[5] via P2P/IPC
kml-dtmachine-13390-prod:34130:34482 [3] NCCL INFO Channel 00 : 11[3] -> 12[4] via SHM/direct/direct
kml-dtmachine-13390-prod:34130:34482 [3] NCCL INFO Channel 01 : 11[3] -> 12[4] via SHM/direct/direct
kml-dtmachine-13390-prod:34128:34483 [1] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34134:34478 [6] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34129:34480 [2] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34132:34485 [5] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34131:34481 [4] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34130:34482 [3] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34128:34483 [1] NCCL INFO Channel 00/0 : 9[1] -> 8[0] via P2P/IPC
kml-dtmachine-13390-prod:34134:34478 [6] NCCL INFO Channel 00/0 : 14[6] -> 13[5] via P2P/IPC
kml-dtmachine-13390-prod:34129:34480 [2] NCCL INFO Channel 00/0 : 10[2] -> 9[1] via P2P/IPC
kml-dtmachine-13390-prod:34132:34485 [5] NCCL INFO Channel 00/0 : 13[5] -> 12[4] via P2P/IPC
kml-dtmachine-13390-prod:34128:34483 [1] NCCL INFO Channel 01/0 : 9[1] -> 8[0] via P2P/IPC
kml-dtmachine-13390-prod:34134:34478 [6] NCCL INFO Channel 01/0 : 14[6] -> 13[5] via P2P/IPC
kml-dtmachine-13390-prod:34129:34480 [2] NCCL INFO Channel 01/0 : 10[2] -> 9[1] via P2P/IPC
kml-dtmachine-13390-prod:34132:34485 [5] NCCL INFO Channel 01/0 : 13[5] -> 12[4] via P2P/IPC
kml-dtmachine-13390-prod:34131:34481 [4] NCCL INFO Channel 00 : 12[4] -> 11[3] via SHM/direct/direct
kml-dtmachine-13390-prod:34131:34481 [4] NCCL INFO Channel 01 : 12[4] -> 11[3] via SHM/direct/direct
kml-dtmachine-13390-prod:34132:34485 [5] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34132:34485 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34132:34485 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34132:34485 [5] NCCL INFO NCCL_P2P_PXN_LEVEL set by environment to 1.
kml-dtmachine-13390-prod:34136:34479 [7] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34136:34479 [7] NCCL INFO Channel 00/0 : 15[7] -> 14[6] via P2P/IPC
kml-dtmachine-13390-prod:34136:34479 [7] NCCL INFO Channel 01/0 : 15[7] -> 14[6] via P2P/IPC
kml-dtmachine-13390-prod:34136:34479 [7] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34136:34479 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34136:34479 [7] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34130:34482 [3] NCCL INFO Channel 00/0 : 11[3] -> 10[2] via P2P/IPC
kml-dtmachine-13390-prod:34136:34479 [7] NCCL INFO NCCL_P2P_PXN_LEVEL set by environment to 1.
kml-dtmachine-13390-prod:34134:34478 [6] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34134:34478 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34134:34478 [6] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34130:34482 [3] NCCL INFO Channel 01/0 : 11[3] -> 10[2] via P2P/IPC
kml-dtmachine-13390-prod:34129:34480 [2] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34129:34480 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34129:34480 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34130:34482 [3] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34130:34482 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34130:34482 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34134:34478 [6] NCCL INFO NCCL_P2P_PXN_LEVEL set by environment to 1.
kml-dtmachine-13390-prod:34131:34481 [4] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34131:34481 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34131:34481 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34129:34480 [2] NCCL INFO NCCL_P2P_PXN_LEVEL set by environment to 1.
kml-dtmachine-13390-prod:34130:34482 [3] NCCL INFO NCCL_P2P_PXN_LEVEL set by environment to 1.
kml-dtmachine-13390-prod:34131:34481 [4] NCCL INFO NCCL_P2P_PXN_LEVEL set by environment to 1.
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34127:34499 [0] NCCL INFO NET/Socket: Using 4 threads and 2 sockets per thread
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO Channel 00/0 : 0[0] -> 8[0] [receive] via NET/Socket/0
kml-dtmachine-13390-prod:34127:34499 [0] NCCL INFO NET/Socket: Using 4 threads and 2 sockets per thread
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO Channel 01/0 : 0[0] -> 8[0] [receive] via NET/Socket/0
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO Channel 00/0 : 8[0] -> 0[0] [send] via NET/Socket/0
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO Channel 01/0 : 8[0] -> 0[0] [send] via NET/Socket/0
kml-dtmachine-13390-prod:34128:34483 [1] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34128:34483 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34128:34483 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34128:34483 [1] NCCL INFO NCCL_P2P_PXN_LEVEL set by environment to 1.
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO NCCL_P2P_PXN_LEVEL set by environment to 1.
kml-dtmachine-13390-prod:34127:34484 [0] NCCL INFO comm 0x7b18d3f0 rank 8 nranks 16 cudaDev 0 nvmlDev 0 busId 35000 commId 0x403f453a942ea82e - Init COMPLETE
kml-dtmachine-13390-prod:34131:34481 [4] NCCL INFO comm 0x797c3820 rank 12 nranks 16 cudaDev 4 nvmlDev 4 busId ce000 commId 0x403f453a942ea82e - Init COMPLETE
kml-dtmachine-13390-prod:34128:34483 [1] NCCL INFO comm 0x7b6d3b20 rank 9 nranks 16 cudaDev 1 nvmlDev 1 busId 36000 commId 0x403f453a942ea82e - Init COMPLETE
kml-dtmachine-13390-prod:34130:34482 [3] NCCL INFO comm 0x7b148260 rank 11 nranks 16 cudaDev 3 nvmlDev 3 busId 3d000 commId 0x403f453a942ea82e - Init COMPLETE
kml-dtmachine-13390-prod:34129:34480 [2] NCCL INFO comm 0x7a894f60 rank 10 nranks 16 cudaDev 2 nvmlDev 2 busId 39000 commId 0x403f453a942ea82e - Init COMPLETE
kml-dtmachine-13390-prod:34134:34478 [6] NCCL INFO comm 0x797f79e0 rank 14 nranks 16 cudaDev 6 nvmlDev 6 busId d2000 commId 0x403f453a942ea82e - Init COMPLETE
kml-dtmachine-13390-prod:34136:34479 [7] NCCL INFO comm 0x7a6f26a0 rank 15 nranks 16 cudaDev 7 nvmlDev 7 busId d6000 commId 0x403f453a942ea82e - Init COMPLETE
kml-dtmachine-13390-prod:34132:34485 [5] NCCL INFO comm 0x7b07d1d0 rank 13 nranks 16 cudaDev 5 nvmlDev 5 busId cf000 commId 0x403f453a942ea82e - Init COMPLETE
/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/initialize.py:358: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /root/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/initialize.py:358: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /root/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/initialize.py:358: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /root/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/initialize.py:358: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /root/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/initialize.py:358: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /root/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/initialize.py:358: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /root/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/initialize.py:358: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /root/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/initialize.py:358: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /root/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /root/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /root/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /root/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /root/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /root/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /root/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /root/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /root/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
No existing process group found, creating a new group named: ep_size_1
No existing process group found, creating a new group named: ep_size_1
No existing process group found, creating a new group named: ep_size_1
No existing process group found, creating a new group named: ep_size_1No existing process group found, creating a new group named: ep_size_1

No existing process group found, creating a new group named: ep_size_1
No existing process group found, creating a new group named: ep_size_1
No existing process group found, creating a new group named: ep_size_1
kml-dtmachine-13390-prod:34131:34564 [4] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34130:34565 [3] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34128:34569 [1] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34127:34570 [0] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34136:34571 [7] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34134:34568 [6] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34129:34567 [2] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34132:34566 [5] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34136:34571 [7] NCCL INFO comm 0x7bb7fa40 rank 15 nranks 16 cudaDev 7 nvmlDev 7 busId d6000 commId 0x76c7837098965be8 - Init START
kml-dtmachine-13390-prod:34134:34568 [6] NCCL INFO comm 0x7c158480 rank 14 nranks 16 cudaDev 6 nvmlDev 6 busId d2000 commId 0x76c7837098965be8 - Init START
kml-dtmachine-13390-prod:34128:34569 [1] NCCL INFO comm 0x7d438d40 rank 9 nranks 16 cudaDev 1 nvmlDev 1 busId 36000 commId 0x76c7837098965be8 - Init START
kml-dtmachine-13390-prod:34127:34570 [0] NCCL INFO comm 0x7c5b21c0 rank 8 nranks 16 cudaDev 0 nvmlDev 0 busId 35000 commId 0x76c7837098965be8 - Init START
kml-dtmachine-13390-prod:34131:34564 [4] NCCL INFO comm 0x7c1c73c0 rank 12 nranks 16 cudaDev 4 nvmlDev 4 busId ce000 commId 0x76c7837098965be8 - Init START
kml-dtmachine-13390-prod:34132:34566 [5] NCCL INFO comm 0x7c402680 rank 13 nranks 16 cudaDev 5 nvmlDev 5 busId cf000 commId 0x76c7837098965be8 - Init START
kml-dtmachine-13390-prod:34130:34565 [3] NCCL INFO comm 0x7c3ca8c0 rank 11 nranks 16 cudaDev 3 nvmlDev 3 busId 3d000 commId 0x76c7837098965be8 - Init START
kml-dtmachine-13390-prod:34129:34567 [2] NCCL INFO comm 0x7bab3580 rank 10 nranks 16 cudaDev 2 nvmlDev 2 busId 39000 commId 0x76c7837098965be8 - Init START
kml-dtmachine-13390-prod:34127:34570 [0] NCCL INFO Setting affinity for GPU 0 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34127:34570 [0] NCCL INFO NVLS multicast support is not available on dev 0
kml-dtmachine-13390-prod:34131:34564 [4] NCCL INFO Setting affinity for GPU 4 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34131:34564 [4] NCCL INFO NVLS multicast support is not available on dev 4
kml-dtmachine-13390-prod:34136:34571 [7] NCCL INFO Setting affinity for GPU 7 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34136:34571 [7] NCCL INFO NVLS multicast support is not available on dev 7
kml-dtmachine-13390-prod:34128:34569 [1] NCCL INFO Setting affinity for GPU 1 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34128:34569 [1] NCCL INFO NVLS multicast support is not available on dev 1
kml-dtmachine-13390-prod:34129:34567 [2] NCCL INFO Setting affinity for GPU 2 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34129:34567 [2] NCCL INFO NVLS multicast support is not available on dev 2
kml-dtmachine-13390-prod:34132:34566 [5] NCCL INFO Setting affinity for GPU 5 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34134:34568 [6] NCCL INFO Setting affinity for GPU 6 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34132:34566 [5] NCCL INFO NVLS multicast support is not available on dev 5
kml-dtmachine-13390-prod:34134:34568 [6] NCCL INFO NVLS multicast support is not available on dev 6
kml-dtmachine-13390-prod:34130:34565 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34130:34565 [3] NCCL INFO NVLS multicast support is not available on dev 3
kml-dtmachine-13390-prod:34127:34570 [0] NCCL INFO Trees [0] 9/-1/-1->8->0 [1] 9/0/-1->8->-1
kml-dtmachine-13390-prod:34129:34567 [2] NCCL INFO Trees [0] 11/-1/-1->10->9 [1] 11/-1/-1->10->9
kml-dtmachine-13390-prod:34136:34571 [7] NCCL INFO Trees [0] -1/-1/-1->15->14 [1] -1/-1/-1->15->14
kml-dtmachine-13390-prod:34127:34570 [0] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34129:34567 [2] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34131:34564 [4] NCCL INFO Trees [0] 13/-1/-1->12->11 [1] 13/-1/-1->12->11
kml-dtmachine-13390-prod:34136:34571 [7] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34131:34564 [4] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34130:34565 [3] NCCL INFO Trees [0] 12/-1/-1->11->10 [1] 12/-1/-1->11->10
kml-dtmachine-13390-prod:34130:34565 [3] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34134:34568 [6] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13
kml-dtmachine-13390-prod:34128:34569 [1] NCCL INFO Trees [0] 10/-1/-1->9->8 [1] 10/-1/-1->9->8
kml-dtmachine-13390-prod:34132:34566 [5] NCCL INFO Trees [0] 14/-1/-1->13->12 [1] 14/-1/-1->13->12
kml-dtmachine-13390-prod:34134:34568 [6] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34128:34569 [1] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34132:34566 [5] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34127:34581 [0] NCCL INFO NET/Socket: Using 4 threads and 2 sockets per thread
kml-dtmachine-13390-prod:34127:34570 [0] NCCL INFO Channel 00/0 : 7[7] -> 8[0] [receive] via NET/Socket/0
kml-dtmachine-13390-prod:34127:34581 [0] NCCL INFO NET/Socket: Using 4 threads and 2 sockets per thread
kml-dtmachine-13390-prod:34127:34570 [0] NCCL INFO Channel 01/0 : 7[7] -> 8[0] [receive] via NET/Socket/0
kml-dtmachine-13390-prod:34127:34570 [0] NCCL INFO Channel 00/0 : 8[0] -> 9[1] via P2P/IPC
kml-dtmachine-13390-prod:34127:34570 [0] NCCL INFO Channel 01/0 : 8[0] -> 9[1] via P2P/IPC
kml-dtmachine-13390-prod:34129:34567 [2] NCCL INFO Channel 00/0 : 10[2] -> 11[3] via P2P/IPC
kml-dtmachine-13390-prod:34132:34566 [5] NCCL INFO Channel 00/0 : 13[5] -> 14[6] via P2P/IPC
kml-dtmachine-13390-prod:34136:34571 [7] NCCL INFO Channel 00/0 : 15[7] -> 0[0] [send] via NET/Socket/0
kml-dtmachine-13390-prod:34136:34571 [7] NCCL INFO Channel 01/0 : 15[7] -> 0[0] [send] via NET/Socket/0
kml-dtmachine-13390-prod:34128:34569 [1] NCCL INFO Channel 00/0 : 9[1] -> 10[2] via P2P/IPC
kml-dtmachine-13390-prod:34134:34568 [6] NCCL INFO Channel 00/0 : 14[6] -> 15[7] via P2P/IPC
kml-dtmachine-13390-prod:34131:34564 [4] NCCL INFO Channel 00/0 : 12[4] -> 13[5] via P2P/IPC
kml-dtmachine-13390-prod:34130:34565 [3] NCCL INFO Channel 00 : 11[3] -> 12[4] via SHM/direct/direct
kml-dtmachine-13390-prod:34129:34567 [2] NCCL INFO Channel 01/0 : 10[2] -> 11[3] via P2P/IPC
kml-dtmachine-13390-prod:34132:34566 [5] NCCL INFO Channel 01/0 : 13[5] -> 14[6] via P2P/IPC
kml-dtmachine-13390-prod:34134:34568 [6] NCCL INFO Channel 01/0 : 14[6] -> 15[7] via P2P/IPC
kml-dtmachine-13390-prod:34131:34564 [4] NCCL INFO Channel 01/0 : 12[4] -> 13[5] via P2P/IPC
kml-dtmachine-13390-prod:34130:34565 [3] NCCL INFO Channel 01 : 11[3] -> 12[4] via SHM/direct/direct
kml-dtmachine-13390-prod:34128:34569 [1] NCCL INFO Channel 01/0 : 9[1] -> 10[2] via P2P/IPC
kml-dtmachine-13390-prod:34132:34566 [5] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34131:34564 [4] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34134:34568 [6] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34130:34565 [3] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34132:34566 [5] NCCL INFO Channel 00/0 : 13[5] -> 12[4] via P2P/IPC
kml-dtmachine-13390-prod:34129:34567 [2] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34128:34569 [1] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34132:34566 [5] NCCL INFO Channel 01/0 : 13[5] -> 12[4] via P2P/IPC
kml-dtmachine-13390-prod:34134:34568 [6] NCCL INFO Channel 00/0 : 14[6] -> 13[5] via P2P/IPC
kml-dtmachine-13390-prod:34131:34564 [4] NCCL INFO Channel 00 : 12[4] -> 11[3] via SHM/direct/direct
kml-dtmachine-13390-prod:34134:34568 [6] NCCL INFO Channel 01/0 : 14[6] -> 13[5] via P2P/IPC
kml-dtmachine-13390-prod:34131:34564 [4] NCCL INFO Channel 01 : 12[4] -> 11[3] via SHM/direct/direct
kml-dtmachine-13390-prod:34129:34567 [2] NCCL INFO Channel 00/0 : 10[2] -> 9[1] via P2P/IPC
kml-dtmachine-13390-prod:34129:34567 [2] NCCL INFO Channel 01/0 : 10[2] -> 9[1] via P2P/IPC
kml-dtmachine-13390-prod:34128:34569 [1] NCCL INFO Channel 00/0 : 9[1] -> 8[0] via P2P/IPC
kml-dtmachine-13390-prod:34128:34569 [1] NCCL INFO Channel 01/0 : 9[1] -> 8[0] via P2P/IPC
kml-dtmachine-13390-prod:34132:34566 [5] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34132:34566 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34132:34566 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34130:34565 [3] NCCL INFO Channel 00/0 : 11[3] -> 10[2] via P2P/IPC
kml-dtmachine-13390-prod:34130:34565 [3] NCCL INFO Channel 01/0 : 11[3] -> 10[2] via P2P/IPC
kml-dtmachine-13390-prod:34129:34567 [2] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34129:34567 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34129:34567 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34130:34565 [3] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34130:34565 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34130:34565 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34131:34564 [4] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34131:34564 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34131:34564 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34136:34571 [7] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34136:34571 [7] NCCL INFO Channel 00/0 : 15[7] -> 14[6] via P2P/IPC
kml-dtmachine-13390-prod:34136:34571 [7] NCCL INFO Channel 01/0 : 15[7] -> 14[6] via P2P/IPC
kml-dtmachine-13390-prod:34136:34571 [7] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34136:34571 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34136:34571 [7] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34134:34568 [6] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34134:34568 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34134:34568 [6] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34127:34570 [0] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34127:34581 [0] NCCL INFO NET/Socket: Using 4 threads and 2 sockets per thread
kml-dtmachine-13390-prod:34127:34570 [0] NCCL INFO Channel 00/0 : 0[0] -> 8[0] [receive] via NET/Socket/0
kml-dtmachine-13390-prod:34127:34581 [0] NCCL INFO NET/Socket: Using 4 threads and 2 sockets per thread
kml-dtmachine-13390-prod:34127:34570 [0] NCCL INFO Channel 01/0 : 0[0] -> 8[0] [receive] via NET/Socket/0
kml-dtmachine-13390-prod:34127:34570 [0] NCCL INFO Channel 00/0 : 8[0] -> 0[0] [send] via NET/Socket/0
kml-dtmachine-13390-prod:34127:34570 [0] NCCL INFO Channel 01/0 : 8[0] -> 0[0] [send] via NET/Socket/0
kml-dtmachine-13390-prod:34128:34569 [1] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34128:34569 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34128:34569 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34127:34570 [0] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34127:34570 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34127:34570 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34127:34570 [0] NCCL INFO comm 0x7c5b21c0 rank 8 nranks 16 cudaDev 0 nvmlDev 0 busId 35000 commId 0x76c7837098965be8 - Init COMPLETE
kml-dtmachine-13390-prod:34131:34564 [4] NCCL INFO comm 0x7c1c73c0 rank 12 nranks 16 cudaDev 4 nvmlDev 4 busId ce000 commId 0x76c7837098965be8 - Init COMPLETE
kml-dtmachine-13390-prod:34128:34569 [1] NCCL INFO comm 0x7d438d40 rank 9 nranks 16 cudaDev 1 nvmlDev 1 busId 36000 commId 0x76c7837098965be8 - Init COMPLETE
kml-dtmachine-13390-prod:34131:34600 [4] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34127:34601 [0] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34128:34603 [1] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34136:34571 [7] NCCL INFO comm 0x7bb7fa40 rank 15 nranks 16 cudaDev 7 nvmlDev 7 busId d6000 commId 0x76c7837098965be8 - Init COMPLETE
kml-dtmachine-13390-prod:34132:34566 [5] NCCL INFO comm 0x7c402680 rank 13 nranks 16 cudaDev 5 nvmlDev 5 busId cf000 commId 0x76c7837098965be8 - Init COMPLETE
kml-dtmachine-13390-prod:34130:34565 [3] NCCL INFO comm 0x7c3ca8c0 rank 11 nranks 16 cudaDev 3 nvmlDev 3 busId 3d000 commId 0x76c7837098965be8 - Init COMPLETE
kml-dtmachine-13390-prod:34136:34611 [7] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34132:34612 [5] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34130:34613 [3] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34129:34567 [2] NCCL INFO comm 0x7bab3580 rank 10 nranks 16 cudaDev 2 nvmlDev 2 busId 39000 commId 0x76c7837098965be8 - Init COMPLETE
kml-dtmachine-13390-prod:34134:34568 [6] NCCL INFO comm 0x7c158480 rank 14 nranks 16 cudaDev 6 nvmlDev 6 busId d2000 commId 0x76c7837098965be8 - Init COMPLETE
kml-dtmachine-13390-prod:34129:34614 [2] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34134:34615 [6] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34136:34611 [7] NCCL INFO comm 0x7bb83b40 rank 15 nranks 16 cudaDev 7 nvmlDev 7 busId d6000 commId 0xf17ff3ad7eaf781d - Init START
kml-dtmachine-13390-prod:34134:34615 [6] NCCL INFO comm 0x7c15c580 rank 14 nranks 16 cudaDev 6 nvmlDev 6 busId d2000 commId 0xf17ff3ad7eaf781d - Init START
kml-dtmachine-13390-prod:34130:34613 [3] NCCL INFO comm 0x7c6353c0 rank 11 nranks 16 cudaDev 3 nvmlDev 3 busId 3d000 commId 0xf17ff3ad7eaf781d - Init START
kml-dtmachine-13390-prod:34129:34614 [2] NCCL INFO comm 0x7bb22100 rank 10 nranks 16 cudaDev 2 nvmlDev 2 busId 39000 commId 0xf17ff3ad7eaf781d - Init START
kml-dtmachine-13390-prod:34132:34612 [5] NCCL INFO comm 0x7dbb0b00 rank 13 nranks 16 cudaDev 5 nvmlDev 5 busId cf000 commId 0xf17ff3ad7eaf781d - Init START
kml-dtmachine-13390-prod:34128:34603 [1] NCCL INFO comm 0x7c81c700 rank 9 nranks 16 cudaDev 1 nvmlDev 1 busId 36000 commId 0xf17ff3ad7eaf781d - Init START
kml-dtmachine-13390-prod:34131:34600 [4] NCCL INFO comm 0x7b3bbf80 rank 12 nranks 16 cudaDev 4 nvmlDev 4 busId ce000 commId 0xf17ff3ad7eaf781d - Init START
kml-dtmachine-13390-prod:34127:34601 [0] NCCL INFO comm 0x7c5b62c0 rank 8 nranks 16 cudaDev 0 nvmlDev 0 busId 35000 commId 0xf17ff3ad7eaf781d - Init START
kml-dtmachine-13390-prod:34128:34603 [1] NCCL INFO Setting affinity for GPU 1 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34128:34603 [1] NCCL INFO NVLS multicast support is not available on dev 1
kml-dtmachine-13390-prod:34134:34615 [6] NCCL INFO Setting affinity for GPU 6 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34134:34615 [6] NCCL INFO NVLS multicast support is not available on dev 6
kml-dtmachine-13390-prod:34136:34611 [7] NCCL INFO Setting affinity for GPU 7 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34136:34611 [7] NCCL INFO NVLS multicast support is not available on dev 7
kml-dtmachine-13390-prod:34127:34601 [0] NCCL INFO Setting affinity for GPU 0 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34127:34601 [0] NCCL INFO NVLS multicast support is not available on dev 0
kml-dtmachine-13390-prod:34130:34613 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34129:34614 [2] NCCL INFO Setting affinity for GPU 2 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34129:34614 [2] NCCL INFO NVLS multicast support is not available on dev 2
kml-dtmachine-13390-prod:34131:34600 [4] NCCL INFO Setting affinity for GPU 4 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34131:34600 [4] NCCL INFO NVLS multicast support is not available on dev 4
kml-dtmachine-13390-prod:34132:34612 [5] NCCL INFO Setting affinity for GPU 5 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34132:34612 [5] NCCL INFO NVLS multicast support is not available on dev 5
kml-dtmachine-13390-prod:34130:34613 [3] NCCL INFO NVLS multicast support is not available on dev 3
kml-dtmachine-13390-prod:34128:34603 [1] NCCL INFO Trees [0] 10/-1/-1->9->8 [1] 10/-1/-1->9->8
kml-dtmachine-13390-prod:34127:34601 [0] NCCL INFO Trees [0] 9/-1/-1->8->0 [1] 9/0/-1->8->-1
kml-dtmachine-13390-prod:34136:34611 [7] NCCL INFO Trees [0] -1/-1/-1->15->14 [1] -1/-1/-1->15->14
kml-dtmachine-13390-prod:34129:34614 [2] NCCL INFO Trees [0] 11/-1/-1->10->9 [1] 11/-1/-1->10->9
kml-dtmachine-13390-prod:34128:34603 [1] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34131:34600 [4] NCCL INFO Trees [0] 13/-1/-1->12->11 [1] 13/-1/-1->12->11
kml-dtmachine-13390-prod:34127:34601 [0] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34130:34613 [3] NCCL INFO Trees [0] 12/-1/-1->11->10 [1] 12/-1/-1->11->10
kml-dtmachine-13390-prod:34136:34611 [7] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34129:34614 [2] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34132:34612 [5] NCCL INFO Trees [0] 14/-1/-1->13->12 [1] 14/-1/-1->13->12
kml-dtmachine-13390-prod:34131:34600 [4] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34130:34613 [3] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34132:34612 [5] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34134:34615 [6] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13
kml-dtmachine-13390-prod:34134:34615 [6] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34127:34620 [0] NCCL INFO NET/Socket: Using 4 threads and 2 sockets per thread
kml-dtmachine-13390-prod:34127:34601 [0] NCCL INFO Channel 00/0 : 7[7] -> 8[0] [receive] via NET/Socket/0
kml-dtmachine-13390-prod:34127:34620 [0] NCCL INFO NET/Socket: Using 4 threads and 2 sockets per thread
kml-dtmachine-13390-prod:34127:34601 [0] NCCL INFO Channel 01/0 : 7[7] -> 8[0] [receive] via NET/Socket/0
kml-dtmachine-13390-prod:34127:34601 [0] NCCL INFO Channel 00/0 : 8[0] -> 9[1] via P2P/IPC
kml-dtmachine-13390-prod:34127:34601 [0] NCCL INFO Channel 01/0 : 8[0] -> 9[1] via P2P/IPC
kml-dtmachine-13390-prod:34129:34614 [2] NCCL INFO Channel 00/0 : 10[2] -> 11[3] via P2P/IPC
kml-dtmachine-13390-prod:34136:34611 [7] NCCL INFO Channel 00/0 : 15[7] -> 0[0] [send] via NET/Socket/0
kml-dtmachine-13390-prod:34136:34611 [7] NCCL INFO Channel 01/0 : 15[7] -> 0[0] [send] via NET/Socket/0
kml-dtmachine-13390-prod:34134:34615 [6] NCCL INFO Channel 00/0 : 14[6] -> 15[7] via P2P/IPC
kml-dtmachine-13390-prod:34132:34612 [5] NCCL INFO Channel 00/0 : 13[5] -> 14[6] via P2P/IPC
kml-dtmachine-13390-prod:34128:34603 [1] NCCL INFO Channel 00/0 : 9[1] -> 10[2] via P2P/IPC
kml-dtmachine-13390-prod:34131:34600 [4] NCCL INFO Channel 00/0 : 12[4] -> 13[5] via P2P/IPC
kml-dtmachine-13390-prod:34129:34614 [2] NCCL INFO Channel 01/0 : 10[2] -> 11[3] via P2P/IPC
kml-dtmachine-13390-prod:34130:34613 [3] NCCL INFO Channel 00 : 11[3] -> 12[4] via SHM/direct/direct
kml-dtmachine-13390-prod:34132:34612 [5] NCCL INFO Channel 01/0 : 13[5] -> 14[6] via P2P/IPC
kml-dtmachine-13390-prod:34128:34603 [1] NCCL INFO Channel 01/0 : 9[1] -> 10[2] via P2P/IPC
kml-dtmachine-13390-prod:34134:34615 [6] NCCL INFO Channel 01/0 : 14[6] -> 15[7] via P2P/IPC
kml-dtmachine-13390-prod:34131:34600 [4] NCCL INFO Channel 01/0 : 12[4] -> 13[5] via P2P/IPC
kml-dtmachine-13390-prod:34130:34613 [3] NCCL INFO Channel 01 : 11[3] -> 12[4] via SHM/direct/direct
kml-dtmachine-13390-prod:34129:34614 [2] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34128:34603 [1] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34132:34612 [5] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34134:34615 [6] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34131:34600 [4] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34130:34613 [3] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34129:34614 [2] NCCL INFO Channel 00/0 : 10[2] -> 9[1] via P2P/IPC
kml-dtmachine-13390-prod:34128:34603 [1] NCCL INFO Channel 00/0 : 9[1] -> 8[0] via P2P/IPC
kml-dtmachine-13390-prod:34132:34612 [5] NCCL INFO Channel 00/0 : 13[5] -> 12[4] via P2P/IPC
kml-dtmachine-13390-prod:34134:34615 [6] NCCL INFO Channel 00/0 : 14[6] -> 13[5] via P2P/IPC
kml-dtmachine-13390-prod:34129:34614 [2] NCCL INFO Channel 01/0 : 10[2] -> 9[1] via P2P/IPC
kml-dtmachine-13390-prod:34128:34603 [1] NCCL INFO Channel 01/0 : 9[1] -> 8[0] via P2P/IPC
kml-dtmachine-13390-prod:34132:34612 [5] NCCL INFO Channel 01/0 : 13[5] -> 12[4] via P2P/IPC
kml-dtmachine-13390-prod:34136:34611 [7] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34134:34615 [6] NCCL INFO Channel 01/0 : 14[6] -> 13[5] via P2P/IPC
kml-dtmachine-13390-prod:34136:34611 [7] NCCL INFO Channel 00/0 : 15[7] -> 14[6] via P2P/IPC
kml-dtmachine-13390-prod:34131:34600 [4] NCCL INFO Channel 00 : 12[4] -> 11[3] via SHM/direct/direct
kml-dtmachine-13390-prod:34136:34611 [7] NCCL INFO Channel 01/0 : 15[7] -> 14[6] via P2P/IPC
kml-dtmachine-13390-prod:34131:34600 [4] NCCL INFO Channel 01 : 12[4] -> 11[3] via SHM/direct/direct
kml-dtmachine-13390-prod:34136:34611 [7] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34136:34611 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34136:34611 [7] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34132:34612 [5] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34134:34615 [6] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34132:34612 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34132:34612 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34134:34615 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34134:34615 [6] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34130:34613 [3] NCCL INFO Channel 00/0 : 11[3] -> 10[2] via P2P/IPC
kml-dtmachine-13390-prod:34130:34613 [3] NCCL INFO Channel 01/0 : 11[3] -> 10[2] via P2P/IPC
kml-dtmachine-13390-prod:34129:34614 [2] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34129:34614 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34129:34614 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34130:34613 [3] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34130:34613 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34130:34613 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34131:34600 [4] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34131:34600 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34131:34600 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34127:34601 [0] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34127:34620 [0] NCCL INFO NET/Socket: Using 4 threads and 2 sockets per thread
kml-dtmachine-13390-prod:34127:34601 [0] NCCL INFO Channel 00/0 : 0[0] -> 8[0] [receive] via NET/Socket/0
kml-dtmachine-13390-prod:34127:34620 [0] NCCL INFO NET/Socket: Using 4 threads and 2 sockets per thread
kml-dtmachine-13390-prod:34127:34601 [0] NCCL INFO Channel 01/0 : 0[0] -> 8[0] [receive] via NET/Socket/0
kml-dtmachine-13390-prod:34127:34601 [0] NCCL INFO Channel 00/0 : 8[0] -> 0[0] [send] via NET/Socket/0
kml-dtmachine-13390-prod:34127:34601 [0] NCCL INFO Channel 01/0 : 8[0] -> 0[0] [send] via NET/Socket/0
kml-dtmachine-13390-prod:34128:34603 [1] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34128:34603 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34128:34603 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34127:34601 [0] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34127:34601 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
kml-dtmachine-13390-prod:34127:34601 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
kml-dtmachine-13390-prod:34127:34601 [0] NCCL INFO comm 0x7c5b62c0 rank 8 nranks 16 cudaDev 0 nvmlDev 0 busId 35000 commId 0xf17ff3ad7eaf781d - Init COMPLETE
kml-dtmachine-13390-prod:34131:34600 [4] NCCL INFO comm 0x7b3bbf80 rank 12 nranks 16 cudaDev 4 nvmlDev 4 busId ce000 commId 0xf17ff3ad7eaf781d - Init COMPLETE
kml-dtmachine-13390-prod:34129:34614 [2] NCCL INFO comm 0x7bb22100 rank 10 nranks 16 cudaDev 2 nvmlDev 2 busId 39000 commId 0xf17ff3ad7eaf781d - Init COMPLETE
kml-dtmachine-13390-prod:34128:34603 [1] NCCL INFO comm 0x7c81c700 rank 9 nranks 16 cudaDev 1 nvmlDev 1 busId 36000 commId 0xf17ff3ad7eaf781d - Init COMPLETE
kml-dtmachine-13390-prod:34136:34611 [7] NCCL INFO comm 0x7bb83b40 rank 15 nranks 16 cudaDev 7 nvmlDev 7 busId d6000 commId 0xf17ff3ad7eaf781d - Init COMPLETE
kml-dtmachine-13390-prod:34130:34613 [3] NCCL INFO comm 0x7c6353c0 rank 11 nranks 16 cudaDev 3 nvmlDev 3 busId 3d000 commId 0xf17ff3ad7eaf781d - Init COMPLETE
kml-dtmachine-13390-prod:34134:34615 [6] NCCL INFO comm 0x7c15c580 rank 14 nranks 16 cudaDev 6 nvmlDev 6 busId d2000 commId 0xf17ff3ad7eaf781d - Init COMPLETE
kml-dtmachine-13390-prod:34132:34612 [5] NCCL INFO comm 0x7dbb0b00 rank 13 nranks 16 cudaDev 5 nvmlDev 5 busId cf000 commId 0xf17ff3ad7eaf781d - Init COMPLETE
[2023-12-27 23:46:42,447] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/examples_deepspeed/MoE/output_1227/checkpoint/gpt-1.3BB-lr-2.0e-4-minlr-2.0e-5-bs-128-gpus-16-mp-1-pp-1-top1-ep-16-mlc-0.01-cap-1.0-drop-true/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2023-12-27 23:46:42,447] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/examples_deepspeed/MoE/output_1227/checkpoint/gpt-1.3BB-lr-2.0e-4-minlr-2.0e-5-bs-128-gpus-16-mp-1-pp-1-top1-ep-16-mlc-0.01-cap-1.0-drop-true/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2023-12-27 23:46:42,447] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/examples_deepspeed/MoE/output_1227/checkpoint/gpt-1.3BB-lr-2.0e-4-minlr-2.0e-5-bs-128-gpus-16-mp-1-pp-1-top1-ep-16-mlc-0.01-cap-1.0-drop-true/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2023-12-27 23:46:42,447] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/examples_deepspeed/MoE/output_1227/checkpoint/gpt-1.3BB-lr-2.0e-4-minlr-2.0e-5-bs-128-gpus-16-mp-1-pp-1-top1-ep-16-mlc-0.01-cap-1.0-drop-true/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2023-12-27 23:46:42,447] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/examples_deepspeed/MoE/output_1227/checkpoint/gpt-1.3BB-lr-2.0e-4-minlr-2.0e-5-bs-128-gpus-16-mp-1-pp-1-top1-ep-16-mlc-0.01-cap-1.0-drop-true/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2023-12-27 23:46:42,447] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/examples_deepspeed/MoE/output_1227/checkpoint/gpt-1.3BB-lr-2.0e-4-minlr-2.0e-5-bs-128-gpus-16-mp-1-pp-1-top1-ep-16-mlc-0.01-cap-1.0-drop-true/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2023-12-27 23:46:42,447] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/examples_deepspeed/MoE/output_1227/checkpoint/gpt-1.3BB-lr-2.0e-4-minlr-2.0e-5-bs-128-gpus-16-mp-1-pp-1-top1-ep-16-mlc-0.01-cap-1.0-drop-true/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2023-12-27 23:46:42,447] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/examples_deepspeed/MoE/output_1227/checkpoint/gpt-1.3BB-lr-2.0e-4-minlr-2.0e-5-bs-128-gpus-16-mp-1-pp-1-top1-ep-16-mlc-0.01-cap-1.0-drop-true/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
(min, max) time across ranks (ms):
    load-checkpoint ................................: (51.38, 51.66)
NCCL version 2.18.3+cuda12.1
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Using network Socket
NCCL version 2.18.3+cuda12.1
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Using network Socket
NCCL version 2.18.3+cuda12.1
NCCL version 2.18.3+cuda12.1
NCCL version 2.18.3+cuda12.1
NCCL version 2.18.3+cuda12.1
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO comm 0x7dbaed20 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 35000 commId 0x6830d5f126539d8a - Init START
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO comm 0x7c2bd450 rank 0 nranks 1 cudaDev 7 nvmlDev 7 busId d6000 commId 0x473c1f93f9baf944 - Init START
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO comm 0x7c8c9c40 rank 0 nranks 1 cudaDev 1 nvmlDev 1 busId 36000 commId 0xaab7f8de91f61aa6 - Init START
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO comm 0x7d27d640 rank 0 nranks 1 cudaDev 2 nvmlDev 2 busId 39000 commId 0x315599fe94982940 - Init START
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO comm 0x7e3cc500 rank 0 nranks 1 cudaDev 5 nvmlDev 5 busId cf000 commId 0x57119989ac83069a - Init START
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO comm 0x7b50a4c0 rank 0 nranks 1 cudaDev 6 nvmlDev 6 busId d2000 commId 0x87a9c69ca22e166 - Init START
NCCL version 2.18.3+cuda12.1
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Using network Socket
NCCL version 2.18.3+cuda12.1
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO comm 0x7aa00e80 rank 0 nranks 1 cudaDev 4 nvmlDev 4 busId ce000 commId 0x695bd25313898504 - Init START
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO comm 0x7ce25000 rank 0 nranks 1 cudaDev 3 nvmlDev 3 busId 3d000 commId 0x22247e4e1ea13ca - Init START
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Setting affinity for GPU 1 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Setting affinity for GPU 0 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Setting affinity for GPU 7 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Setting affinity for GPU 2 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Setting affinity for GPU 5 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Setting affinity for GPU 6 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Setting affinity for GPU 4 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34136:34795 [7] NCCL INFO comm 0x7c2bd450 rank 0 nranks 1 cudaDev 7 nvmlDev 7 busId d6000 commId 0x473c1f93f9baf944 - Init COMPLETE
kml-dtmachine-13390-prod:34127:34793 [0] NCCL INFO comm 0x7dbaed20 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 35000 commId 0x6830d5f126539d8a - Init COMPLETE
kml-dtmachine-13390-prod:34128:34797 [1] NCCL INFO comm 0x7c8c9c40 rank 0 nranks 1 cudaDev 1 nvmlDev 1 busId 36000 commId 0xaab7f8de91f61aa6 - Init COMPLETE
kml-dtmachine-13390-prod:34129:34800 [2] NCCL INFO comm 0x7d27d640 rank 0 nranks 1 cudaDev 2 nvmlDev 2 busId 39000 commId 0x315599fe94982940 - Init COMPLETE
kml-dtmachine-13390-prod:34132:34802 [5] NCCL INFO comm 0x7e3cc500 rank 0 nranks 1 cudaDev 5 nvmlDev 5 busId cf000 commId 0x57119989ac83069a - Init COMPLETE
kml-dtmachine-13390-prod:34134:34803 [6] NCCL INFO comm 0x7b50a4c0 rank 0 nranks 1 cudaDev 6 nvmlDev 6 busId d2000 commId 0x87a9c69ca22e166 - Init COMPLETE
kml-dtmachine-13390-prod:34130:34808 [3] NCCL INFO comm 0x7ce25000 rank 0 nranks 1 cudaDev 3 nvmlDev 3 busId 3d000 commId 0x22247e4e1ea13ca - Init COMPLETE
kml-dtmachine-13390-prod:34131:34805 [4] NCCL INFO comm 0x7aa00e80 rank 0 nranks 1 cudaDev 4 nvmlDev 4 busId ce000 commId 0x695bd25313898504 - Init COMPLETE
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO comm 0x7d2a20c0 rank 0 nranks 1 cudaDev 2 nvmlDev 2 busId 39000 commId 0x8b3401fc4041d902 - Init START
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO comm 0x7b530ce0 rank 0 nranks 1 cudaDev 6 nvmlDev 6 busId d2000 commId 0xdc711fa6f15aab9a - Init START
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO comm 0x7e3f2b00 rank 0 nranks 1 cudaDev 5 nvmlDev 5 busId cf000 commId 0xbb5705cf36196417 - Init START
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO comm 0x7ce4b7d0 rank 0 nranks 1 cudaDev 3 nvmlDev 3 busId 3d000 commId 0x33237f0d8e5a9e25 - Init START
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO comm 0x7dbb7f00 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 35000 commId 0x66f13bada3b6742 - Init START
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO comm 0x7c2c6420 rank 0 nranks 1 cudaDev 7 nvmlDev 7 busId d6000 commId 0xcdc77bc0f6bdf256 - Init START
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO comm 0x7c8eeba0 rank 0 nranks 1 cudaDev 1 nvmlDev 1 busId 36000 commId 0x39c47c3de1b164c8 - Init START
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO comm 0x7aa27360 rank 0 nranks 1 cudaDev 4 nvmlDev 4 busId ce000 commId 0x3c643272c020c210 - Init START
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Setting affinity for GPU 2 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Setting affinity for GPU 6 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Setting affinity for GPU 5 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Setting affinity for GPU 0 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Setting affinity for GPU 7 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Setting affinity for GPU 1 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Setting affinity for GPU 4 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34129:34829 [2] NCCL INFO comm 0x7d2a20c0 rank 0 nranks 1 cudaDev 2 nvmlDev 2 busId 39000 commId 0x8b3401fc4041d902 - Init COMPLETE
kml-dtmachine-13390-prod:34130:34839 [3] NCCL INFO comm 0x7ce4b7d0 rank 0 nranks 1 cudaDev 3 nvmlDev 3 busId 3d000 commId 0x33237f0d8e5a9e25 - Init COMPLETE
kml-dtmachine-13390-prod:34132:34833 [5] NCCL INFO comm 0x7e3f2b00 rank 0 nranks 1 cudaDev 5 nvmlDev 5 busId cf000 commId 0xbb5705cf36196417 - Init COMPLETE
kml-dtmachine-13390-prod:34136:34837 [7] NCCL INFO comm 0x7c2c6420 rank 0 nranks 1 cudaDev 7 nvmlDev 7 busId d6000 commId 0xcdc77bc0f6bdf256 - Init COMPLETE
kml-dtmachine-13390-prod:34127:34838 [0] NCCL INFO comm 0x7dbb7f00 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 35000 commId 0x66f13bada3b6742 - Init COMPLETE
kml-dtmachine-13390-prod:34128:34841 [1] NCCL INFO comm 0x7c8eeba0 rank 0 nranks 1 cudaDev 1 nvmlDev 1 busId 36000 commId 0x39c47c3de1b164c8 - Init COMPLETE
kml-dtmachine-13390-prod:34134:34832 [6] NCCL INFO comm 0x7b530ce0 rank 0 nranks 1 cudaDev 6 nvmlDev 6 busId d2000 commId 0xdc711fa6f15aab9a - Init COMPLETE
kml-dtmachine-13390-prod:34131:34843 [4] NCCL INFO comm 0x7aa27360 rank 0 nranks 1 cudaDev 4 nvmlDev 4 busId ce000 commId 0x3c643272c020c210 - Init COMPLETE
(min, max) time across ranks (ms):
    model-and-optimizer-setup ......................: (80005.87, 80006.20)
    train/valid/test-data-iterators-setup ..........: (2153.51, 2638.13)
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO comm 0xf50e6810 rank 0 nranks 1 cudaDev 2 nvmlDev 2 busId 39000 commId 0x9063de0a6b3034ac - Init START
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Setting affinity for GPU 2 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34129:34885 [2] NCCL INFO comm 0xf50e6810 rank 0 nranks 1 cudaDev 2 nvmlDev 2 busId 39000 commId 0x9063de0a6b3034ac - Init COMPLETE
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO comm 0xf4036e20 rank 0 nranks 1 cudaDev 4 nvmlDev 4 busId ce000 commId 0xa46a6690ab327e2f - Init START
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Setting affinity for GPU 4 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO comm 0xf59da9d0 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 35000 commId 0x975ee5c15fe4e154 - Init START
kml-dtmachine-13390-prod:34131:34892 [4] NCCL INFO comm 0xf4036e20 rank 0 nranks 1 cudaDev 4 nvmlDev 4 busId ce000 commId 0xa46a6690ab327e2f - Init COMPLETE
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Setting affinity for GPU 0 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34127:34896 [0] NCCL INFO comm 0xf59da9d0 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 35000 commId 0x975ee5c15fe4e154 - Init COMPLETE
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO comm 0xf4f45ad0 rank 0 nranks 1 cudaDev 7 nvmlDev 7 busId d6000 commId 0xc2f1aec94313b125 - Init START
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO comm 0xf58cbe30 rank 0 nranks 1 cudaDev 5 nvmlDev 5 busId cf000 commId 0x51f0e860ea6b0529 - Init START
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Setting affinity for GPU 7 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO comm 0xf59c0770 rank 0 nranks 1 cudaDev 3 nvmlDev 3 busId 3d000 commId 0x3957e43f2586df35 - Init START
kml-dtmachine-13390-prod:34136:34900 [7] NCCL INFO comm 0xf4f45ad0 rank 0 nranks 1 cudaDev 7 nvmlDev 7 busId d6000 commId 0xc2f1aec94313b125 - Init COMPLETE
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Setting affinity for GPU 5 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34132:34902 [5] NCCL INFO comm 0xf58cbe30 rank 0 nranks 1 cudaDev 5 nvmlDev 5 busId cf000 commId 0x51f0e860ea6b0529 - Init COMPLETE
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO comm 0xf5f47800 rank 0 nranks 1 cudaDev 1 nvmlDev 1 busId 36000 commId 0x74c9087bde916104 - Init START
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Using network Socket
kml-dtmachine-13390-prod:34130:34906 [3] NCCL INFO comm 0xf59c0770 rank 0 nranks 1 cudaDev 3 nvmlDev 3 busId 3d000 commId 0x3957e43f2586df35 - Init COMPLETE
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO comm 0xf406af40 rank 0 nranks 1 cudaDev 6 nvmlDev 6 busId d2000 commId 0xe048c9e069962e6c - Init START
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Setting affinity for GPU 1 to ffffffff,00000000,ffffffff
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Setting affinity for GPU 6 to ffffffff,00000000,ffffffff,00000000
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 00/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 01/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 02/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 03/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 04/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 05/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 06/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 07/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 08/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 09/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 10/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 11/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 12/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 13/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 14/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 15/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 16/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 17/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 18/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 19/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 20/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 21/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 22/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 23/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 24/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 25/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 26/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 27/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 28/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 29/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 30/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Channel 31/32 :    0
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO P2P Chunksize set to 131072
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Connected all rings
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO Connected all trees
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
kml-dtmachine-13390-prod:34134:34914 [6] NCCL INFO comm 0xf406af40 rank 0 nranks 1 cudaDev 6 nvmlDev 6 busId d2000 commId 0xe048c9e069962e6c - Init COMPLETE
kml-dtmachine-13390-prod:34128:34910 [1] NCCL INFO comm 0xf5f47800 rank 0 nranks 1 cudaDev 1 nvmlDev 1 busId 36000 commId 0x74c9087bde916104 - Init COMPLETE
 iteration       10/   11444 | consumed samples:         1280 | consumed tokens:      2621440 | elapsed time per iteration (ms): 12365.4 | learning rate: 2.000E-04 | global batch size:   128 | lm loss: 1.036803E+01 | moe loss: 2.183898E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 10.351 | tokens per gpu per second (tgs): 1324.989 | TFLOPs: 11.82 |
 iteration       20/   11444 | consumed samples:         2560 | consumed tokens:      5242880 | elapsed time per iteration (ms): 9976.4 | learning rate: 2.000E-04 | global batch size:   128 | lm loss: 7.744951E+00 | moe loss: 1.993083E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 12.830 | tokens per gpu per second (tgs): 1642.273 | TFLOPs: 14.65 |
 iteration       30/   11444 | consumed samples:         3840 | consumed tokens:      7864320 | elapsed time per iteration (ms): 9506.4 | learning rate: 2.000E-04 | global batch size:   128 | lm loss: 7.415761E+00 | moe loss: 1.750215E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.465 | tokens per gpu per second (tgs): 1723.472 | TFLOPs: 15.37 |
 iteration       40/   11444 | consumed samples:         5120 | consumed tokens:     10485760 | elapsed time per iteration (ms): 9473.3 | learning rate: 2.000E-04 | global batch size:   128 | lm loss: 7.298194E+00 | moe loss: 1.508714E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.512 | tokens per gpu per second (tgs): 1729.498 | TFLOPs: 15.43 |
 iteration       50/   11444 | consumed samples:         6400 | consumed tokens:     13107200 | elapsed time per iteration (ms): 9227.8 | learning rate: 2.000E-04 | global batch size:   128 | lm loss: 7.263593E+00 | moe loss: 1.383699E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.871 | tokens per gpu per second (tgs): 1775.510 | TFLOPs: 15.84 |
 iteration       60/   11444 | consumed samples:         7680 | consumed tokens:     15728640 | elapsed time per iteration (ms): 9476.9 | learning rate: 2.000E-04 | global batch size:   128 | lm loss: 7.227253E+00 | moe loss: 1.309480E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.506 | tokens per gpu per second (tgs): 1728.829 | TFLOPs: 15.42 |
 iteration       70/   11444 | consumed samples:         8960 | consumed tokens:     18350080 | elapsed time per iteration (ms): 9193.0 | learning rate: 2.000E-04 | global batch size:   128 | lm loss: 7.040917E+00 | moe loss: 1.283963E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.924 | tokens per gpu per second (tgs): 1782.220 | TFLOPs: 15.90 |
 iteration       80/   11444 | consumed samples:        10240 | consumed tokens:     20971520 | elapsed time per iteration (ms): 9493.0 | learning rate: 2.000E-04 | global batch size:   128 | lm loss: 6.908224E+00 | moe loss: 1.285331E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.484 | tokens per gpu per second (tgs): 1725.895 | TFLOPs: 15.39 |
 iteration       90/   11444 | consumed samples:        11520 | consumed tokens:     23592960 | elapsed time per iteration (ms): 9580.8 | learning rate: 1.999E-04 | global batch size:   128 | lm loss: 6.795125E+00 | moe loss: 1.262217E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.360 | tokens per gpu per second (tgs): 1710.080 | TFLOPs: 15.25 |
 iteration      100/   11444 | consumed samples:        12800 | consumed tokens:     26214400 | elapsed time per iteration (ms): 9366.0 | learning rate: 1.999E-04 | global batch size:   128 | lm loss: 6.805655E+00 | moe loss: 1.241262E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.666 | tokens per gpu per second (tgs): 1749.307 | TFLOPs: 15.60 |
 iteration      110/   11444 | consumed samples:        14080 | consumed tokens:     28835840 | elapsed time per iteration (ms): 9413.9 | learning rate: 1.999E-04 | global batch size:   128 | lm loss: 6.759173E+00 | moe loss: 1.239105E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.597 | tokens per gpu per second (tgs): 1740.412 | TFLOPs: 15.52 |
 iteration      120/   11444 | consumed samples:        15360 | consumed tokens:     31457280 | elapsed time per iteration (ms): 9387.9 | learning rate: 1.999E-04 | global batch size:   128 | lm loss: 6.568826E+00 | moe loss: 1.232731E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.635 | tokens per gpu per second (tgs): 1745.232 | TFLOPs: 15.57 |
 iteration      130/   11444 | consumed samples:        16640 | consumed tokens:     34078720 | elapsed time per iteration (ms): 9376.0 | learning rate: 1.999E-04 | global batch size:   128 | lm loss: 6.558900E+00 | moe loss: 1.241928E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.652 | tokens per gpu per second (tgs): 1747.445 | TFLOPs: 15.59 |
 iteration      140/   11444 | consumed samples:        17920 | consumed tokens:     36700160 | elapsed time per iteration (ms): 9494.5 | learning rate: 1.999E-04 | global batch size:   128 | lm loss: 6.494105E+00 | moe loss: 1.241749E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.481 | tokens per gpu per second (tgs): 1725.623 | TFLOPs: 15.39 |
 iteration      150/   11444 | consumed samples:        19200 | consumed tokens:     39321600 | elapsed time per iteration (ms): 9430.2 | learning rate: 1.998E-04 | global batch size:   128 | lm loss: 6.412224E+00 | moe loss: 1.249511E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.573 | tokens per gpu per second (tgs): 1737.400 | TFLOPs: 15.50 |
 iteration      160/   11444 | consumed samples:        20480 | consumed tokens:     41943040 | elapsed time per iteration (ms): 9580.1 | learning rate: 1.998E-04 | global batch size:   128 | lm loss: 6.297725E+00 | moe loss: 1.240694E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.361 | tokens per gpu per second (tgs): 1710.206 | TFLOPs: 15.25 |
 iteration      170/   11444 | consumed samples:        21760 | consumed tokens:     44564480 | elapsed time per iteration (ms): 9136.4 | learning rate: 1.998E-04 | global batch size:   128 | lm loss: 6.258926E+00 | moe loss: 1.259416E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.010 | tokens per gpu per second (tgs): 1793.272 | TFLOPs: 15.99 |
 iteration      180/   11444 | consumed samples:        23040 | consumed tokens:     47185920 | elapsed time per iteration (ms): 9195.0 | learning rate: 1.998E-04 | global batch size:   128 | lm loss: 6.226228E+00 | moe loss: 1.249944E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.921 | tokens per gpu per second (tgs): 1781.835 | TFLOPs: 15.89 |
 iteration      190/   11444 | consumed samples:        24320 | consumed tokens:     49807360 | elapsed time per iteration (ms): 9173.5 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 6.126054E+00 | moe loss: 1.242995E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.953 | tokens per gpu per second (tgs): 1786.014 | TFLOPs: 15.93 |
 iteration      200/   11444 | consumed samples:        25600 | consumed tokens:     52428800 | elapsed time per iteration (ms): 9169.6 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 6.099345E+00 | moe loss: 1.260210E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.959 | tokens per gpu per second (tgs): 1786.772 | TFLOPs: 15.94 |
 iteration      210/   11444 | consumed samples:        26880 | consumed tokens:     55050240 | elapsed time per iteration (ms): 8999.8 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 6.128717E+00 | moe loss: 1.243617E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.223 | tokens per gpu per second (tgs): 1820.488 | TFLOPs: 16.24 |
 iteration      220/   11444 | consumed samples:        28160 | consumed tokens:     57671680 | elapsed time per iteration (ms): 9143.9 | learning rate: 1.996E-04 | global batch size:   128 | lm loss: 6.033814E+00 | moe loss: 1.245094E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.998 | tokens per gpu per second (tgs): 1791.791 | TFLOPs: 15.98 |
 iteration      230/   11444 | consumed samples:        29440 | consumed tokens:     60293120 | elapsed time per iteration (ms): 9275.4 | learning rate: 1.996E-04 | global batch size:   128 | lm loss: 5.967390E+00 | moe loss: 1.247475E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.800 | tokens per gpu per second (tgs): 1766.388 | TFLOPs: 15.75 |
 iteration      240/   11444 | consumed samples:        30720 | consumed tokens:     62914560 | elapsed time per iteration (ms): 9290.3 | learning rate: 1.996E-04 | global batch size:   128 | lm loss: 5.918387E+00 | moe loss: 1.253160E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.778 | tokens per gpu per second (tgs): 1763.560 | TFLOPs: 15.73 |
 iteration      250/   11444 | consumed samples:        32000 | consumed tokens:     65536000 | elapsed time per iteration (ms): 9262.5 | learning rate: 1.995E-04 | global batch size:   128 | lm loss: 5.898933E+00 | moe loss: 1.241959E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.819 | tokens per gpu per second (tgs): 1768.852 | TFLOPs: 15.78 |
 iteration      260/   11444 | consumed samples:        33280 | consumed tokens:     68157440 | elapsed time per iteration (ms): 9455.9 | learning rate: 1.995E-04 | global batch size:   128 | lm loss: 5.770741E+00 | moe loss: 1.246048E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.537 | tokens per gpu per second (tgs): 1732.680 | TFLOPs: 15.45 |
 iteration      270/   11444 | consumed samples:        34560 | consumed tokens:     70778880 | elapsed time per iteration (ms): 9467.0 | learning rate: 1.995E-04 | global batch size:   128 | lm loss: 5.754785E+00 | moe loss: 1.248802E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.521 | tokens per gpu per second (tgs): 1730.636 | TFLOPs: 15.44 |
 iteration      280/   11444 | consumed samples:        35840 | consumed tokens:     73400320 | elapsed time per iteration (ms): 9277.3 | learning rate: 1.994E-04 | global batch size:   128 | lm loss: 5.739042E+00 | moe loss: 1.244285E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.797 | tokens per gpu per second (tgs): 1766.032 | TFLOPs: 15.75 |
 iteration      290/   11444 | consumed samples:        37120 | consumed tokens:     76021760 | elapsed time per iteration (ms): 9168.7 | learning rate: 1.994E-04 | global batch size:   128 | lm loss: 5.674169E+00 | moe loss: 1.243984E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.960 | tokens per gpu per second (tgs): 1786.942 | TFLOPs: 15.94 |
 iteration      300/   11444 | consumed samples:        38400 | consumed tokens:     78643200 | elapsed time per iteration (ms): 9297.9 | learning rate: 1.993E-04 | global batch size:   128 | lm loss: 5.585419E+00 | moe loss: 1.246739E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.767 | tokens per gpu per second (tgs): 1762.118 | TFLOPs: 15.72 |
 iteration      310/   11444 | consumed samples:        39680 | consumed tokens:     81264640 | elapsed time per iteration (ms): 9493.4 | learning rate: 1.993E-04 | global batch size:   128 | lm loss: 5.545850E+00 | moe loss: 1.246804E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.483 | tokens per gpu per second (tgs): 1725.839 | TFLOPs: 15.39 |
 iteration      320/   11444 | consumed samples:        40960 | consumed tokens:     83886080 | elapsed time per iteration (ms): 9155.7 | learning rate: 1.992E-04 | global batch size:   128 | lm loss: 5.607445E+00 | moe loss: 1.239915E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.980 | tokens per gpu per second (tgs): 1789.486 | TFLOPs: 15.96 |
 iteration      330/   11444 | consumed samples:        42240 | consumed tokens:     86507520 | elapsed time per iteration (ms): 9572.8 | learning rate: 1.992E-04 | global batch size:   128 | lm loss: 5.489822E+00 | moe loss: 1.246290E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.371 | tokens per gpu per second (tgs): 1711.515 | TFLOPs: 15.27 |
 iteration      340/   11444 | consumed samples:        43520 | consumed tokens:     89128960 | elapsed time per iteration (ms): 9197.4 | learning rate: 1.991E-04 | global batch size:   128 | lm loss: 5.438538E+00 | moe loss: 1.243077E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.917 | tokens per gpu per second (tgs): 1781.375 | TFLOPs: 15.89 |
 iteration      350/   11444 | consumed samples:        44800 | consumed tokens:     91750400 | elapsed time per iteration (ms): 9242.2 | learning rate: 1.991E-04 | global batch size:   128 | lm loss: 5.390991E+00 | moe loss: 1.238515E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.850 | tokens per gpu per second (tgs): 1772.737 | TFLOPs: 15.81 |
 iteration      360/   11444 | consumed samples:        46080 | consumed tokens:     94371840 | elapsed time per iteration (ms): 9197.4 | learning rate: 1.990E-04 | global batch size:   128 | lm loss: 5.410589E+00 | moe loss: 1.240700E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.917 | tokens per gpu per second (tgs): 1781.366 | TFLOPs: 15.89 |
 iteration      370/   11444 | consumed samples:        47360 | consumed tokens:     96993280 | elapsed time per iteration (ms): 9138.0 | learning rate: 1.990E-04 | global batch size:   128 | lm loss: 5.328617E+00 | moe loss: 1.244633E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.007 | tokens per gpu per second (tgs): 1792.953 | TFLOPs: 15.99 |
 iteration      380/   11444 | consumed samples:        48640 | consumed tokens:     99614720 | elapsed time per iteration (ms): 8973.6 | learning rate: 1.989E-04 | global batch size:   128 | lm loss: 5.272499E+00 | moe loss: 1.236367E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.264 | tokens per gpu per second (tgs): 1825.809 | TFLOPs: 16.28 |
 iteration      390/   11444 | consumed samples:        49920 | consumed tokens:    102236160 | elapsed time per iteration (ms): 9301.5 | learning rate: 1.989E-04 | global batch size:   128 | lm loss: 5.265865E+00 | moe loss: 1.237847E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.761 | tokens per gpu per second (tgs): 1761.439 | TFLOPs: 15.71 |
 iteration      400/   11444 | consumed samples:        51200 | consumed tokens:    104857600 | elapsed time per iteration (ms): 9140.5 | learning rate: 1.988E-04 | global batch size:   128 | lm loss: 5.201865E+00 | moe loss: 1.238982E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.004 | tokens per gpu per second (tgs): 1792.466 | TFLOPs: 15.99 |
 iteration      410/   11444 | consumed samples:        52480 | consumed tokens:    107479040 | elapsed time per iteration (ms): 9058.8 | learning rate: 1.988E-04 | global batch size:   128 | lm loss: 5.198560E+00 | moe loss: 1.244257E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.130 | tokens per gpu per second (tgs): 1808.631 | TFLOPs: 16.13 |
 iteration      420/   11444 | consumed samples:        53760 | consumed tokens:    110100480 | elapsed time per iteration (ms): 9024.4 | learning rate: 1.987E-04 | global batch size:   128 | lm loss: 5.183374E+00 | moe loss: 1.243585E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.184 | tokens per gpu per second (tgs): 1815.519 | TFLOPs: 16.19 |
 iteration      430/   11444 | consumed samples:        55040 | consumed tokens:    112721920 | elapsed time per iteration (ms): 8970.0 | learning rate: 1.986E-04 | global batch size:   128 | lm loss: 5.138345E+00 | moe loss: 1.240397E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.270 | tokens per gpu per second (tgs): 1826.537 | TFLOPs: 16.29 |
 iteration      440/   11444 | consumed samples:        56320 | consumed tokens:    115343360 | elapsed time per iteration (ms): 9068.7 | learning rate: 1.986E-04 | global batch size:   128 | lm loss: 5.152710E+00 | moe loss: 1.236873E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.114 | tokens per gpu per second (tgs): 1806.650 | TFLOPs: 16.11 |
 iteration      450/   11444 | consumed samples:        57600 | consumed tokens:    117964800 | elapsed time per iteration (ms): 8959.3 | learning rate: 1.985E-04 | global batch size:   128 | lm loss: 5.053439E+00 | moe loss: 1.239140E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.287 | tokens per gpu per second (tgs): 1828.719 | TFLOPs: 16.31 |
 iteration      460/   11444 | consumed samples:        58880 | consumed tokens:    120586240 | elapsed time per iteration (ms): 8931.2 | learning rate: 1.984E-04 | global batch size:   128 | lm loss: 5.088130E+00 | moe loss: 1.231901E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.332 | tokens per gpu per second (tgs): 1834.471 | TFLOPs: 16.36 |
 iteration      470/   11444 | consumed samples:        60160 | consumed tokens:    123207680 | elapsed time per iteration (ms): 8907.6 | learning rate: 1.984E-04 | global batch size:   128 | lm loss: 5.039145E+00 | moe loss: 1.245288E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.370 | tokens per gpu per second (tgs): 1839.319 | TFLOPs: 16.41 |
 iteration      480/   11444 | consumed samples:        61440 | consumed tokens:    125829120 | elapsed time per iteration (ms): 9239.8 | learning rate: 1.983E-04 | global batch size:   128 | lm loss: 5.013763E+00 | moe loss: 1.233709E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.853 | tokens per gpu per second (tgs): 1773.204 | TFLOPs: 15.82 |
 iteration      490/   11444 | consumed samples:        62720 | consumed tokens:    128450560 | elapsed time per iteration (ms): 8927.4 | learning rate: 1.982E-04 | global batch size:   128 | lm loss: 5.009843E+00 | moe loss: 1.239343E-01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.338 | tokens per gpu per second (tgs): 1835.248 | TFLOPs: 16.37 |
 iteration      500/   11444 | consumed samples:        64000 | consumed tokens:    131072000 | elapsed time per iteration (ms): 9210.3 | learning rate: 1.981E-04 | global batch size:   128 | lm loss: 4.948224E+00 | moe loss: 1.242530E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.897 | tokens per gpu per second (tgs): 1778.880 | TFLOPs: 15.87 |
 iteration      510/   11444 | consumed samples:        65280 | consumed tokens:    133693440 | elapsed time per iteration (ms): 9112.2 | learning rate: 1.981E-04 | global batch size:   128 | lm loss: 4.903147E+00 | moe loss: 1.231268E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.047 | tokens per gpu per second (tgs): 1798.029 | TFLOPs: 16.04 |
 iteration      520/   11444 | consumed samples:        66560 | consumed tokens:    136314880 | elapsed time per iteration (ms): 9092.1 | learning rate: 1.980E-04 | global batch size:   128 | lm loss: 4.936808E+00 | moe loss: 1.240188E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.078 | tokens per gpu per second (tgs): 1802.001 | TFLOPs: 16.07 |
 iteration      530/   11444 | consumed samples:        67840 | consumed tokens:    138936320 | elapsed time per iteration (ms): 9125.8 | learning rate: 1.979E-04 | global batch size:   128 | lm loss: 4.845863E+00 | moe loss: 1.236470E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.026 | tokens per gpu per second (tgs): 1795.351 | TFLOPs: 16.01 |
 iteration      540/   11444 | consumed samples:        69120 | consumed tokens:    141557760 | elapsed time per iteration (ms): 9060.8 | learning rate: 1.978E-04 | global batch size:   128 | lm loss: 4.863528E+00 | moe loss: 1.236217E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.127 | tokens per gpu per second (tgs): 1808.235 | TFLOPs: 16.13 |
 iteration      550/   11444 | consumed samples:        70400 | consumed tokens:    144179200 | elapsed time per iteration (ms): 9130.7 | learning rate: 1.977E-04 | global batch size:   128 | lm loss: 4.818568E+00 | moe loss: 1.233221E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.019 | tokens per gpu per second (tgs): 1794.386 | TFLOPs: 16.00 |
 iteration      560/   11444 | consumed samples:        71680 | consumed tokens:    146800640 | elapsed time per iteration (ms): 8993.4 | learning rate: 1.977E-04 | global batch size:   128 | lm loss: 4.753680E+00 | moe loss: 1.233575E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.233 | tokens per gpu per second (tgs): 1821.774 | TFLOPs: 16.25 |
 iteration      570/   11444 | consumed samples:        72960 | consumed tokens:    149422080 | elapsed time per iteration (ms): 9064.1 | learning rate: 1.976E-04 | global batch size:   128 | lm loss: 4.752908E+00 | moe loss: 1.232727E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.122 | tokens per gpu per second (tgs): 1807.578 | TFLOPs: 16.12 |
 iteration      580/   11444 | consumed samples:        74240 | consumed tokens:    152043520 | elapsed time per iteration (ms): 9176.4 | learning rate: 1.975E-04 | global batch size:   128 | lm loss: 4.755142E+00 | moe loss: 1.235251E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.949 | tokens per gpu per second (tgs): 1785.455 | TFLOPs: 15.93 |
 iteration      590/   11444 | consumed samples:        75520 | consumed tokens:    154664960 | elapsed time per iteration (ms): 9279.0 | learning rate: 1.974E-04 | global batch size:   128 | lm loss: 4.722049E+00 | moe loss: 1.232504E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.795 | tokens per gpu per second (tgs): 1765.717 | TFLOPs: 15.75 |
 iteration      600/   11444 | consumed samples:        76800 | consumed tokens:    157286400 | elapsed time per iteration (ms): 9066.4 | learning rate: 1.973E-04 | global batch size:   128 | lm loss: 4.621087E+00 | moe loss: 1.235631E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.118 | tokens per gpu per second (tgs): 1807.121 | TFLOPs: 16.12 |
 iteration      610/   11444 | consumed samples:        78080 | consumed tokens:    159907840 | elapsed time per iteration (ms): 9249.7 | learning rate: 1.972E-04 | global batch size:   128 | lm loss: 4.624809E+00 | moe loss: 1.233554E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.838 | tokens per gpu per second (tgs): 1771.303 | TFLOPs: 15.80 |
 iteration      620/   11444 | consumed samples:        79360 | consumed tokens:    162529280 | elapsed time per iteration (ms): 9050.1 | learning rate: 1.971E-04 | global batch size:   128 | lm loss: 4.589683E+00 | moe loss: 1.233196E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.144 | tokens per gpu per second (tgs): 1810.371 | TFLOPs: 16.15 |
 iteration      630/   11444 | consumed samples:        80640 | consumed tokens:    165150720 | elapsed time per iteration (ms): 9101.1 | learning rate: 1.970E-04 | global batch size:   128 | lm loss: 4.636460E+00 | moe loss: 1.232771E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.064 | tokens per gpu per second (tgs): 1800.231 | TFLOPs: 16.06 |
 iteration      640/   11444 | consumed samples:        81920 | consumed tokens:    167772160 | elapsed time per iteration (ms): 9289.2 | learning rate: 1.969E-04 | global batch size:   128 | lm loss: 4.563300E+00 | moe loss: 1.237776E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.779 | tokens per gpu per second (tgs): 1763.767 | TFLOPs: 15.73 |
 iteration      650/   11444 | consumed samples:        83200 | consumed tokens:    170393600 | elapsed time per iteration (ms): 9497.4 | learning rate: 1.968E-04 | global batch size:   128 | lm loss: 4.526722E+00 | moe loss: 1.230649E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.477 | tokens per gpu per second (tgs): 1725.103 | TFLOPs: 15.39 |
 iteration      660/   11444 | consumed samples:        84480 | consumed tokens:    173015040 | elapsed time per iteration (ms): 9154.7 | learning rate: 1.967E-04 | global batch size:   128 | lm loss: 4.537598E+00 | moe loss: 1.232072E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.982 | tokens per gpu per second (tgs): 1789.673 | TFLOPs: 15.96 |
 iteration      670/   11444 | consumed samples:        85760 | consumed tokens:    175636480 | elapsed time per iteration (ms): 9225.4 | learning rate: 1.967E-04 | global batch size:   128 | lm loss: 4.457235E+00 | moe loss: 1.230581E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.875 | tokens per gpu per second (tgs): 1775.957 | TFLOPs: 15.84 |
 iteration      680/   11444 | consumed samples:        87040 | consumed tokens:    178257920 | elapsed time per iteration (ms): 9014.5 | learning rate: 1.965E-04 | global batch size:   128 | lm loss: 4.465561E+00 | moe loss: 1.232928E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.199 | tokens per gpu per second (tgs): 1817.514 | TFLOPs: 16.21 |
 iteration      690/   11444 | consumed samples:        88320 | consumed tokens:    180879360 | elapsed time per iteration (ms): 9072.3 | learning rate: 1.964E-04 | global batch size:   128 | lm loss: 4.446969E+00 | moe loss: 1.239920E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.109 | tokens per gpu per second (tgs): 1805.933 | TFLOPs: 16.11 |
 iteration      700/   11444 | consumed samples:        89600 | consumed tokens:    183500800 | elapsed time per iteration (ms): 8951.6 | learning rate: 1.963E-04 | global batch size:   128 | lm loss: 4.445680E+00 | moe loss: 1.239762E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.299 | tokens per gpu per second (tgs): 1830.284 | TFLOPs: 16.32 |
 iteration      710/   11444 | consumed samples:        90880 | consumed tokens:    186122240 | elapsed time per iteration (ms): 9366.3 | learning rate: 1.962E-04 | global batch size:   128 | lm loss: 4.400039E+00 | moe loss: 1.231260E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.666 | tokens per gpu per second (tgs): 1749.247 | TFLOPs: 15.60 |
 iteration      720/   11444 | consumed samples:        92160 | consumed tokens:    188743680 | elapsed time per iteration (ms): 8948.7 | learning rate: 1.961E-04 | global batch size:   128 | lm loss: 4.389386E+00 | moe loss: 1.234609E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.304 | tokens per gpu per second (tgs): 1830.890 | TFLOPs: 16.33 |
 iteration      730/   11444 | consumed samples:        93440 | consumed tokens:    191365120 | elapsed time per iteration (ms): 9021.5 | learning rate: 1.960E-04 | global batch size:   128 | lm loss: 4.322145E+00 | moe loss: 1.233993E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.188 | tokens per gpu per second (tgs): 1816.112 | TFLOPs: 16.20 |
 iteration      740/   11444 | consumed samples:        94720 | consumed tokens:    193986560 | elapsed time per iteration (ms): 9094.4 | learning rate: 1.959E-04 | global batch size:   128 | lm loss: 4.273003E+00 | moe loss: 1.232541E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.075 | tokens per gpu per second (tgs): 1801.538 | TFLOPs: 16.07 |
 iteration      750/   11444 | consumed samples:        96000 | consumed tokens:    196608000 | elapsed time per iteration (ms): 9109.6 | learning rate: 1.958E-04 | global batch size:   128 | lm loss: 4.337392E+00 | moe loss: 1.230152E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.051 | tokens per gpu per second (tgs): 1798.551 | TFLOPs: 16.04 |
 iteration      760/   11444 | consumed samples:        97280 | consumed tokens:    199229440 | elapsed time per iteration (ms): 9202.6 | learning rate: 1.957E-04 | global batch size:   128 | lm loss: 4.277672E+00 | moe loss: 1.231093E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.909 | tokens per gpu per second (tgs): 1780.367 | TFLOPs: 15.88 |
 iteration      770/   11444 | consumed samples:        98560 | consumed tokens:    201850880 | elapsed time per iteration (ms): 9302.5 | learning rate: 1.956E-04 | global batch size:   128 | lm loss: 4.225003E+00 | moe loss: 1.225631E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.760 | tokens per gpu per second (tgs): 1761.254 | TFLOPs: 15.71 |
 iteration      780/   11444 | consumed samples:        99840 | consumed tokens:    204472320 | elapsed time per iteration (ms): 8921.8 | learning rate: 1.955E-04 | global batch size:   128 | lm loss: 4.128012E+00 | moe loss: 1.231590E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.347 | tokens per gpu per second (tgs): 1836.404 | TFLOPs: 16.38 |
 iteration      790/   11444 | consumed samples:       101120 | consumed tokens:    207093760 | elapsed time per iteration (ms): 9097.9 | learning rate: 1.953E-04 | global batch size:   128 | lm loss: 4.119109E+00 | moe loss: 1.229099E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.069 | tokens per gpu per second (tgs): 1800.846 | TFLOPs: 16.06 |
 iteration      800/   11444 | consumed samples:       102400 | consumed tokens:    209715200 | elapsed time per iteration (ms): 9327.3 | learning rate: 1.952E-04 | global batch size:   128 | lm loss: 4.097220E+00 | moe loss: 1.232716E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.723 | tokens per gpu per second (tgs): 1756.569 | TFLOPs: 15.67 |
 iteration      810/   11444 | consumed samples:       103680 | consumed tokens:    212336640 | elapsed time per iteration (ms): 8895.8 | learning rate: 1.951E-04 | global batch size:   128 | lm loss: 4.081020E+00 | moe loss: 1.229513E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.389 | tokens per gpu per second (tgs): 1841.769 | TFLOPs: 16.43 |
 iteration      820/   11444 | consumed samples:       104960 | consumed tokens:    214958080 | elapsed time per iteration (ms): 9001.1 | learning rate: 1.950E-04 | global batch size:   128 | lm loss: 4.104229E+00 | moe loss: 1.228324E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.220 | tokens per gpu per second (tgs): 1820.224 | TFLOPs: 16.24 |
 iteration      830/   11444 | consumed samples:       106240 | consumed tokens:    217579520 | elapsed time per iteration (ms): 8966.5 | learning rate: 1.949E-04 | global batch size:   128 | lm loss: 4.030220E+00 | moe loss: 1.231726E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.275 | tokens per gpu per second (tgs): 1827.245 | TFLOPs: 16.30 |
 iteration      840/   11444 | consumed samples:       107520 | consumed tokens:    220200960 | elapsed time per iteration (ms): 9050.2 | learning rate: 1.947E-04 | global batch size:   128 | lm loss: 4.028978E+00 | moe loss: 1.225737E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.143 | tokens per gpu per second (tgs): 1810.348 | TFLOPs: 16.15 |
 iteration      850/   11444 | consumed samples:       108800 | consumed tokens:    222822400 | elapsed time per iteration (ms): 8916.6 | learning rate: 1.946E-04 | global batch size:   128 | lm loss: 3.954862E+00 | moe loss: 1.229109E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.355 | tokens per gpu per second (tgs): 1837.480 | TFLOPs: 16.39 |
 iteration      860/   11444 | consumed samples:       110080 | consumed tokens:    225443840 | elapsed time per iteration (ms): 9266.0 | learning rate: 1.945E-04 | global batch size:   128 | lm loss: 3.953219E+00 | moe loss: 1.229658E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.814 | tokens per gpu per second (tgs): 1768.178 | TFLOPs: 15.77 |
 iteration      870/   11444 | consumed samples:       111360 | consumed tokens:    228065280 | elapsed time per iteration (ms): 9233.9 | learning rate: 1.944E-04 | global batch size:   128 | lm loss: 3.944394E+00 | moe loss: 1.229007E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.862 | tokens per gpu per second (tgs): 1774.333 | TFLOPs: 15.83 |
 iteration      880/   11444 | consumed samples:       112640 | consumed tokens:    230686720 | elapsed time per iteration (ms): 8917.3 | learning rate: 1.942E-04 | global batch size:   128 | lm loss: 3.896006E+00 | moe loss: 1.227555E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.354 | tokens per gpu per second (tgs): 1837.331 | TFLOPs: 16.39 |
 iteration      890/   11444 | consumed samples:       113920 | consumed tokens:    233308160 | elapsed time per iteration (ms): 9075.8 | learning rate: 1.941E-04 | global batch size:   128 | lm loss: 3.867345E+00 | moe loss: 1.229855E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.103 | tokens per gpu per second (tgs): 1805.246 | TFLOPs: 16.10 |
 iteration      900/   11444 | consumed samples:       115200 | consumed tokens:    235929600 | elapsed time per iteration (ms): 9159.6 | learning rate: 1.940E-04 | global batch size:   128 | lm loss: 3.851477E+00 | moe loss: 1.228250E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.974 | tokens per gpu per second (tgs): 1788.730 | TFLOPs: 15.95 |
 iteration      910/   11444 | consumed samples:       116480 | consumed tokens:    238551040 | elapsed time per iteration (ms): 9381.5 | learning rate: 1.938E-04 | global batch size:   128 | lm loss: 3.869553E+00 | moe loss: 1.232105E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.644 | tokens per gpu per second (tgs): 1746.423 | TFLOPs: 15.58 |
 iteration      920/   11444 | consumed samples:       117760 | consumed tokens:    241172480 | elapsed time per iteration (ms): 9235.4 | learning rate: 1.937E-04 | global batch size:   128 | lm loss: 3.843611E+00 | moe loss: 1.230181E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.860 | tokens per gpu per second (tgs): 1774.048 | TFLOPs: 15.82 |
 iteration      930/   11444 | consumed samples:       119040 | consumed tokens:    243793920 | elapsed time per iteration (ms): 9378.3 | learning rate: 1.936E-04 | global batch size:   128 | lm loss: 3.851138E+00 | moe loss: 1.230481E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.649 | tokens per gpu per second (tgs): 1747.016 | TFLOPs: 15.58 |
 iteration      940/   11444 | consumed samples:       120320 | consumed tokens:    246415360 | elapsed time per iteration (ms): 9581.2 | learning rate: 1.934E-04 | global batch size:   128 | lm loss: 3.828527E+00 | moe loss: 1.228714E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.359 | tokens per gpu per second (tgs): 1710.012 | TFLOPs: 15.25 |
 iteration      950/   11444 | consumed samples:       121600 | consumed tokens:    249036800 | elapsed time per iteration (ms): 9224.6 | learning rate: 1.933E-04 | global batch size:   128 | lm loss: 3.789217E+00 | moe loss: 1.228604E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.876 | tokens per gpu per second (tgs): 1776.111 | TFLOPs: 15.84 |
 iteration      960/   11444 | consumed samples:       122880 | consumed tokens:    251658240 | elapsed time per iteration (ms): 9313.6 | learning rate: 1.931E-04 | global batch size:   128 | lm loss: 3.763380E+00 | moe loss: 1.223936E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.743 | tokens per gpu per second (tgs): 1759.151 | TFLOPs: 15.69 |
 iteration      970/   11444 | consumed samples:       124160 | consumed tokens:    254279680 | elapsed time per iteration (ms): 8919.2 | learning rate: 1.930E-04 | global batch size:   128 | lm loss: 3.790514E+00 | moe loss: 1.225417E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.351 | tokens per gpu per second (tgs): 1836.932 | TFLOPs: 16.38 |
 iteration      980/   11444 | consumed samples:       125440 | consumed tokens:    256901120 | elapsed time per iteration (ms): 9386.9 | learning rate: 1.928E-04 | global batch size:   128 | lm loss: 3.708940E+00 | moe loss: 1.226075E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.636 | tokens per gpu per second (tgs): 1745.413 | TFLOPs: 15.57 |
 iteration      990/   11444 | consumed samples:       126720 | consumed tokens:    259522560 | elapsed time per iteration (ms): 9586.2 | learning rate: 1.927E-04 | global batch size:   128 | lm loss: 3.675452E+00 | moe loss: 1.224445E-01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.353 | tokens per gpu per second (tgs): 1709.129 | TFLOPs: 15.24 |
 iteration     1000/   11444 | consumed samples:       128000 | consumed tokens:    262144000 | elapsed time per iteration (ms): 9404.6 | learning rate: 1.926E-04 | global batch size:   128 | lm loss: 3.642322E+00 | moe loss: 1.230994E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.610 | tokens per gpu per second (tgs): 1742.135 | TFLOPs: 15.54 |
------------------------------------------------------------------------------------------------
 validation loss at iteration 1000 | lm loss value: 3.662889E+00 | lm loss PPL: 3.897379E+01 | 
------------------------------------------------------------------------------------------------
 iteration     1010/   11444 | consumed samples:       129280 | consumed tokens:    264765440 | elapsed time per iteration (ms): 10020.1 | learning rate: 1.924E-04 | global batch size:   128 | lm loss: 3.715083E+00 | moe loss: 1.225537E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 12.774 | tokens per gpu per second (tgs): 1635.107 | TFLOPs: 14.58 |
 iteration     1020/   11444 | consumed samples:       130560 | consumed tokens:    267386880 | elapsed time per iteration (ms): 9289.3 | learning rate: 1.923E-04 | global batch size:   128 | lm loss: 3.700569E+00 | moe loss: 1.224557E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.779 | tokens per gpu per second (tgs): 1763.757 | TFLOPs: 15.73 |
 iteration     1030/   11444 | consumed samples:       131840 | consumed tokens:    270008320 | elapsed time per iteration (ms): 9394.4 | learning rate: 1.921E-04 | global batch size:   128 | lm loss: 3.638254E+00 | moe loss: 1.232442E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.625 | tokens per gpu per second (tgs): 1744.020 | TFLOPs: 15.56 |
 iteration     1040/   11444 | consumed samples:       133120 | consumed tokens:    272629760 | elapsed time per iteration (ms): 9089.1 | learning rate: 1.920E-04 | global batch size:   128 | lm loss: 3.652266E+00 | moe loss: 1.229007E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.083 | tokens per gpu per second (tgs): 1802.596 | TFLOPs: 16.08 |
 iteration     1050/   11444 | consumed samples:       134400 | consumed tokens:    275251200 | elapsed time per iteration (ms): 9087.0 | learning rate: 1.918E-04 | global batch size:   128 | lm loss: 3.575624E+00 | moe loss: 1.227546E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.086 | tokens per gpu per second (tgs): 1803.016 | TFLOPs: 16.08 |
 iteration     1060/   11444 | consumed samples:       135680 | consumed tokens:    277872640 | elapsed time per iteration (ms): 9445.4 | learning rate: 1.916E-04 | global batch size:   128 | lm loss: 3.638946E+00 | moe loss: 1.227483E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.552 | tokens per gpu per second (tgs): 1734.592 | TFLOPs: 15.47 |
 iteration     1070/   11444 | consumed samples:       136960 | consumed tokens:    280494080 | elapsed time per iteration (ms): 9219.2 | learning rate: 1.915E-04 | global batch size:   128 | lm loss: 3.655556E+00 | moe loss: 1.227165E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.884 | tokens per gpu per second (tgs): 1777.158 | TFLOPs: 15.85 |
 iteration     1080/   11444 | consumed samples:       138240 | consumed tokens:    283115520 | elapsed time per iteration (ms): 9276.6 | learning rate: 1.913E-04 | global batch size:   128 | lm loss: 3.578386E+00 | moe loss: 1.224077E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.798 | tokens per gpu per second (tgs): 1766.167 | TFLOPs: 15.75 |
 iteration     1090/   11444 | consumed samples:       139520 | consumed tokens:    285736960 | elapsed time per iteration (ms): 9120.5 | learning rate: 1.912E-04 | global batch size:   128 | lm loss: 3.600554E+00 | moe loss: 1.223029E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.034 | tokens per gpu per second (tgs): 1796.398 | TFLOPs: 16.02 |
 iteration     1100/   11444 | consumed samples:       140800 | consumed tokens:    288358400 | elapsed time per iteration (ms): 9376.4 | learning rate: 1.910E-04 | global batch size:   128 | lm loss: 3.519455E+00 | moe loss: 1.225034E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.651 | tokens per gpu per second (tgs): 1747.359 | TFLOPs: 15.59 |
 iteration     1110/   11444 | consumed samples:       142080 | consumed tokens:    290979840 | elapsed time per iteration (ms): 9270.9 | learning rate: 1.908E-04 | global batch size:   128 | lm loss: 3.522121E+00 | moe loss: 1.230675E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.807 | tokens per gpu per second (tgs): 1767.248 | TFLOPs: 15.76 |
 iteration     1120/   11444 | consumed samples:       143360 | consumed tokens:    293601280 | elapsed time per iteration (ms): 8965.9 | learning rate: 1.907E-04 | global batch size:   128 | lm loss: 3.516343E+00 | moe loss: 1.224648E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.276 | tokens per gpu per second (tgs): 1827.371 | TFLOPs: 16.30 |
 iteration     1130/   11444 | consumed samples:       144640 | consumed tokens:    296222720 | elapsed time per iteration (ms): 9351.8 | learning rate: 1.905E-04 | global batch size:   128 | lm loss: 3.541051E+00 | moe loss: 1.233877E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.687 | tokens per gpu per second (tgs): 1751.968 | TFLOPs: 15.63 |
 iteration     1140/   11444 | consumed samples:       145920 | consumed tokens:    298844160 | elapsed time per iteration (ms): 9296.2 | learning rate: 1.903E-04 | global batch size:   128 | lm loss: 3.565646E+00 | moe loss: 1.230506E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.769 | tokens per gpu per second (tgs): 1762.442 | TFLOPs: 15.72 |
 iteration     1150/   11444 | consumed samples:       147200 | consumed tokens:    301465600 | elapsed time per iteration (ms): 9196.7 | learning rate: 1.902E-04 | global batch size:   128 | lm loss: 3.531524E+00 | moe loss: 1.227354E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.918 | tokens per gpu per second (tgs): 1781.501 | TFLOPs: 15.89 |
 iteration     1160/   11444 | consumed samples:       148480 | consumed tokens:    304087040 | elapsed time per iteration (ms): 9298.0 | learning rate: 1.900E-04 | global batch size:   128 | lm loss: 3.456382E+00 | moe loss: 1.223834E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.766 | tokens per gpu per second (tgs): 1762.105 | TFLOPs: 15.72 |
 iteration     1170/   11444 | consumed samples:       149760 | consumed tokens:    306708480 | elapsed time per iteration (ms): 9528.4 | learning rate: 1.898E-04 | global batch size:   128 | lm loss: 3.515022E+00 | moe loss: 1.221623E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.434 | tokens per gpu per second (tgs): 1719.495 | TFLOPs: 15.34 |
 iteration     1180/   11444 | consumed samples:       151040 | consumed tokens:    309329920 | elapsed time per iteration (ms): 9466.6 | learning rate: 1.897E-04 | global batch size:   128 | lm loss: 3.520190E+00 | moe loss: 1.226589E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.521 | tokens per gpu per second (tgs): 1730.708 | TFLOPs: 15.44 |
 iteration     1190/   11444 | consumed samples:       152320 | consumed tokens:    311951360 | elapsed time per iteration (ms): 9357.0 | learning rate: 1.895E-04 | global batch size:   128 | lm loss: 3.442813E+00 | moe loss: 1.225942E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.680 | tokens per gpu per second (tgs): 1750.996 | TFLOPs: 15.62 |
 iteration     1200/   11444 | consumed samples:       153600 | consumed tokens:    314572800 | elapsed time per iteration (ms): 9176.0 | learning rate: 1.893E-04 | global batch size:   128 | lm loss: 3.445810E+00 | moe loss: 1.225736E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.949 | tokens per gpu per second (tgs): 1785.527 | TFLOPs: 15.93 |
 iteration     1210/   11444 | consumed samples:       154880 | consumed tokens:    317194240 | elapsed time per iteration (ms): 9114.7 | learning rate: 1.891E-04 | global batch size:   128 | lm loss: 3.419085E+00 | moe loss: 1.225695E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.043 | tokens per gpu per second (tgs): 1797.528 | TFLOPs: 16.03 |
 iteration     1220/   11444 | consumed samples:       156160 | consumed tokens:    319815680 | elapsed time per iteration (ms): 9211.2 | learning rate: 1.890E-04 | global batch size:   128 | lm loss: 3.415018E+00 | moe loss: 1.227031E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.896 | tokens per gpu per second (tgs): 1778.702 | TFLOPs: 15.86 |
 iteration     1230/   11444 | consumed samples:       157440 | consumed tokens:    322437120 | elapsed time per iteration (ms): 9175.3 | learning rate: 1.888E-04 | global batch size:   128 | lm loss: 3.455481E+00 | moe loss: 1.225022E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.950 | tokens per gpu per second (tgs): 1785.661 | TFLOPs: 15.93 |
 iteration     1240/   11444 | consumed samples:       158720 | consumed tokens:    325058560 | elapsed time per iteration (ms): 9256.8 | learning rate: 1.886E-04 | global batch size:   128 | lm loss: 3.411661E+00 | moe loss: 1.222353E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.828 | tokens per gpu per second (tgs): 1769.942 | TFLOPs: 15.79 |
 iteration     1250/   11444 | consumed samples:       160000 | consumed tokens:    327680000 | elapsed time per iteration (ms): 9318.8 | learning rate: 1.884E-04 | global batch size:   128 | lm loss: 3.342752E+00 | moe loss: 1.220899E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.736 | tokens per gpu per second (tgs): 1758.159 | TFLOPs: 15.68 |
 iteration     1260/   11444 | consumed samples:       161280 | consumed tokens:    330301440 | elapsed time per iteration (ms): 9450.4 | learning rate: 1.882E-04 | global batch size:   128 | lm loss: 3.395325E+00 | moe loss: 1.226915E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.544 | tokens per gpu per second (tgs): 1733.692 | TFLOPs: 15.46 |
 iteration     1270/   11444 | consumed samples:       162560 | consumed tokens:    332922880 | elapsed time per iteration (ms): 9172.8 | learning rate: 1.881E-04 | global batch size:   128 | lm loss: 3.407018E+00 | moe loss: 1.223665E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.954 | tokens per gpu per second (tgs): 1786.152 | TFLOPs: 15.93 |
 iteration     1280/   11444 | consumed samples:       163840 | consumed tokens:    335544320 | elapsed time per iteration (ms): 9268.1 | learning rate: 1.879E-04 | global batch size:   128 | lm loss: 3.399541E+00 | moe loss: 1.225658E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.811 | tokens per gpu per second (tgs): 1767.787 | TFLOPs: 15.77 |
 iteration     1290/   11444 | consumed samples:       165120 | consumed tokens:    338165760 | elapsed time per iteration (ms): 9392.3 | learning rate: 1.877E-04 | global batch size:   128 | lm loss: 3.410876E+00 | moe loss: 1.223280E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.628 | tokens per gpu per second (tgs): 1744.404 | TFLOPs: 15.56 |
 iteration     1300/   11444 | consumed samples:       166400 | consumed tokens:    340787200 | elapsed time per iteration (ms): 9319.7 | learning rate: 1.875E-04 | global batch size:   128 | lm loss: 3.382788E+00 | moe loss: 1.227320E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.734 | tokens per gpu per second (tgs): 1758.001 | TFLOPs: 15.68 |
 iteration     1310/   11444 | consumed samples:       167680 | consumed tokens:    343408640 | elapsed time per iteration (ms): 9207.8 | learning rate: 1.873E-04 | global batch size:   128 | lm loss: 3.341131E+00 | moe loss: 1.224455E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.901 | tokens per gpu per second (tgs): 1779.361 | TFLOPs: 15.87 |
 iteration     1320/   11444 | consumed samples:       168960 | consumed tokens:    346030080 | elapsed time per iteration (ms): 9146.1 | learning rate: 1.871E-04 | global batch size:   128 | lm loss: 3.371421E+00 | moe loss: 1.226191E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.995 | tokens per gpu per second (tgs): 1791.364 | TFLOPs: 15.98 |
 iteration     1330/   11444 | consumed samples:       170240 | consumed tokens:    348651520 | elapsed time per iteration (ms): 9341.5 | learning rate: 1.869E-04 | global batch size:   128 | lm loss: 3.283662E+00 | moe loss: 1.223298E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.702 | tokens per gpu per second (tgs): 1753.903 | TFLOPs: 15.64 |
 iteration     1340/   11444 | consumed samples:       171520 | consumed tokens:    351272960 | elapsed time per iteration (ms): 9181.2 | learning rate: 1.867E-04 | global batch size:   128 | lm loss: 3.360649E+00 | moe loss: 1.225846E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.941 | tokens per gpu per second (tgs): 1784.508 | TFLOPs: 15.92 |
 iteration     1350/   11444 | consumed samples:       172800 | consumed tokens:    353894400 | elapsed time per iteration (ms): 9349.3 | learning rate: 1.865E-04 | global batch size:   128 | lm loss: 3.361838E+00 | moe loss: 1.224667E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.691 | tokens per gpu per second (tgs): 1752.425 | TFLOPs: 15.63 |
 iteration     1360/   11444 | consumed samples:       174080 | consumed tokens:    356515840 | elapsed time per iteration (ms): 9192.4 | learning rate: 1.863E-04 | global batch size:   128 | lm loss: 3.316278E+00 | moe loss: 1.224027E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.925 | tokens per gpu per second (tgs): 1782.347 | TFLOPs: 15.90 |
 iteration     1370/   11444 | consumed samples:       175360 | consumed tokens:    359137280 | elapsed time per iteration (ms): 9045.4 | learning rate: 1.862E-04 | global batch size:   128 | lm loss: 3.350129E+00 | moe loss: 1.222339E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.151 | tokens per gpu per second (tgs): 1811.301 | TFLOPs: 16.16 |
 iteration     1380/   11444 | consumed samples:       176640 | consumed tokens:    361758720 | elapsed time per iteration (ms): 9277.3 | learning rate: 1.860E-04 | global batch size:   128 | lm loss: 3.323354E+00 | moe loss: 1.222302E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.797 | tokens per gpu per second (tgs): 1766.025 | TFLOPs: 15.75 |
 iteration     1390/   11444 | consumed samples:       177920 | consumed tokens:    364380160 | elapsed time per iteration (ms): 9282.5 | learning rate: 1.858E-04 | global batch size:   128 | lm loss: 3.306549E+00 | moe loss: 1.223612E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.789 | tokens per gpu per second (tgs): 1765.036 | TFLOPs: 15.74 |
 iteration     1400/   11444 | consumed samples:       179200 | consumed tokens:    367001600 | elapsed time per iteration (ms): 9236.5 | learning rate: 1.856E-04 | global batch size:   128 | lm loss: 3.292214E+00 | moe loss: 1.226116E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.858 | tokens per gpu per second (tgs): 1773.826 | TFLOPs: 15.82 |
 iteration     1410/   11444 | consumed samples:       180480 | consumed tokens:    369623040 | elapsed time per iteration (ms): 8994.6 | learning rate: 1.854E-04 | global batch size:   128 | lm loss: 3.312128E+00 | moe loss: 1.225477E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.231 | tokens per gpu per second (tgs): 1821.544 | TFLOPs: 16.25 |
 iteration     1420/   11444 | consumed samples:       181760 | consumed tokens:    372244480 | elapsed time per iteration (ms): 9181.8 | learning rate: 1.851E-04 | global batch size:   128 | lm loss: 3.315754E+00 | moe loss: 1.223612E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.941 | tokens per gpu per second (tgs): 1784.406 | TFLOPs: 15.92 |
 iteration     1430/   11444 | consumed samples:       183040 | consumed tokens:    374865920 | elapsed time per iteration (ms): 9212.3 | learning rate: 1.849E-04 | global batch size:   128 | lm loss: 3.281826E+00 | moe loss: 1.226779E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.894 | tokens per gpu per second (tgs): 1778.495 | TFLOPs: 15.86 |
 iteration     1440/   11444 | consumed samples:       184320 | consumed tokens:    377487360 | elapsed time per iteration (ms): 9495.5 | learning rate: 1.847E-04 | global batch size:   128 | lm loss: 3.286797E+00 | moe loss: 1.225491E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.480 | tokens per gpu per second (tgs): 1725.449 | TFLOPs: 15.39 |
 iteration     1450/   11444 | consumed samples:       185600 | consumed tokens:    380108800 | elapsed time per iteration (ms): 9345.0 | learning rate: 1.845E-04 | global batch size:   128 | lm loss: 3.245477E+00 | moe loss: 1.225604E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.697 | tokens per gpu per second (tgs): 1753.231 | TFLOPs: 15.64 |
 iteration     1460/   11444 | consumed samples:       186880 | consumed tokens:    382730240 | elapsed time per iteration (ms): 9262.5 | learning rate: 1.843E-04 | global batch size:   128 | lm loss: 3.246603E+00 | moe loss: 1.222493E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.819 | tokens per gpu per second (tgs): 1768.862 | TFLOPs: 15.78 |
 iteration     1470/   11444 | consumed samples:       188160 | consumed tokens:    385351680 | elapsed time per iteration (ms): 9245.6 | learning rate: 1.841E-04 | global batch size:   128 | lm loss: 3.260625E+00 | moe loss: 1.223755E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.844 | tokens per gpu per second (tgs): 1772.089 | TFLOPs: 15.81 |
 iteration     1480/   11444 | consumed samples:       189440 | consumed tokens:    387973120 | elapsed time per iteration (ms): 9543.2 | learning rate: 1.839E-04 | global batch size:   128 | lm loss: 3.272801E+00 | moe loss: 1.224636E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.413 | tokens per gpu per second (tgs): 1716.829 | TFLOPs: 15.31 |
 iteration     1490/   11444 | consumed samples:       190720 | consumed tokens:    390594560 | elapsed time per iteration (ms): 9297.9 | learning rate: 1.837E-04 | global batch size:   128 | lm loss: 3.263214E+00 | moe loss: 1.222580E-01 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.766 | tokens per gpu per second (tgs): 1762.111 | TFLOPs: 15.72 |
 iteration     1500/   11444 | consumed samples:       192000 | consumed tokens:    393216000 | elapsed time per iteration (ms): 9166.1 | learning rate: 1.835E-04 | global batch size:   128 | lm loss: 3.249111E+00 | moe loss: 1.223020E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.965 | tokens per gpu per second (tgs): 1787.462 | TFLOPs: 15.94 |
 iteration     1510/   11444 | consumed samples:       193280 | consumed tokens:    395837440 | elapsed time per iteration (ms): 9180.4 | learning rate: 1.833E-04 | global batch size:   128 | lm loss: 3.218958E+00 | moe loss: 1.222746E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.943 | tokens per gpu per second (tgs): 1784.677 | TFLOPs: 15.92 |
 iteration     1520/   11444 | consumed samples:       194560 | consumed tokens:    398458880 | elapsed time per iteration (ms): 8939.8 | learning rate: 1.830E-04 | global batch size:   128 | lm loss: 3.302412E+00 | moe loss: 1.225001E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.318 | tokens per gpu per second (tgs): 1832.707 | TFLOPs: 16.35 |
 iteration     1530/   11444 | consumed samples:       195840 | consumed tokens:    401080320 | elapsed time per iteration (ms): 9311.9 | learning rate: 1.828E-04 | global batch size:   128 | lm loss: 3.231577E+00 | moe loss: 1.224367E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.746 | tokens per gpu per second (tgs): 1759.477 | TFLOPs: 15.69 |
 iteration     1540/   11444 | consumed samples:       197120 | consumed tokens:    403701760 | elapsed time per iteration (ms): 9230.9 | learning rate: 1.826E-04 | global batch size:   128 | lm loss: 3.260266E+00 | moe loss: 1.222699E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.866 | tokens per gpu per second (tgs): 1774.901 | TFLOPs: 15.83 |
 iteration     1550/   11444 | consumed samples:       198400 | consumed tokens:    406323200 | elapsed time per iteration (ms): 9163.7 | learning rate: 1.824E-04 | global batch size:   128 | lm loss: 3.208943E+00 | moe loss: 1.221310E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.968 | tokens per gpu per second (tgs): 1787.932 | TFLOPs: 15.95 |
 iteration     1560/   11444 | consumed samples:       199680 | consumed tokens:    408944640 | elapsed time per iteration (ms): 9139.1 | learning rate: 1.822E-04 | global batch size:   128 | lm loss: 3.214200E+00 | moe loss: 1.226811E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.006 | tokens per gpu per second (tgs): 1792.739 | TFLOPs: 15.99 |
 iteration     1570/   11444 | consumed samples:       200960 | consumed tokens:    411566080 | elapsed time per iteration (ms): 9218.8 | learning rate: 1.819E-04 | global batch size:   128 | lm loss: 3.250743E+00 | moe loss: 1.222123E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.885 | tokens per gpu per second (tgs): 1777.246 | TFLOPs: 15.85 |
 iteration     1580/   11444 | consumed samples:       202240 | consumed tokens:    414187520 | elapsed time per iteration (ms): 9434.1 | learning rate: 1.817E-04 | global batch size:   128 | lm loss: 3.244785E+00 | moe loss: 1.225387E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.568 | tokens per gpu per second (tgs): 1736.683 | TFLOPs: 15.49 |
 iteration     1590/   11444 | consumed samples:       203520 | consumed tokens:    416808960 | elapsed time per iteration (ms): 9252.8 | learning rate: 1.815E-04 | global batch size:   128 | lm loss: 3.163058E+00 | moe loss: 1.222840E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.834 | tokens per gpu per second (tgs): 1770.698 | TFLOPs: 15.79 |
 iteration     1600/   11444 | consumed samples:       204800 | consumed tokens:    419430400 | elapsed time per iteration (ms): 9210.9 | learning rate: 1.813E-04 | global batch size:   128 | lm loss: 3.145426E+00 | moe loss: 1.221504E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.897 | tokens per gpu per second (tgs): 1778.771 | TFLOPs: 15.87 |
 iteration     1610/   11444 | consumed samples:       206080 | consumed tokens:    422051840 | elapsed time per iteration (ms): 9252.6 | learning rate: 1.810E-04 | global batch size:   128 | lm loss: 3.197444E+00 | moe loss: 1.223742E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.834 | tokens per gpu per second (tgs): 1770.737 | TFLOPs: 15.79 |
 iteration     1620/   11444 | consumed samples:       207360 | consumed tokens:    424673280 | elapsed time per iteration (ms): 9277.6 | learning rate: 1.808E-04 | global batch size:   128 | lm loss: 3.171386E+00 | moe loss: 1.223323E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.797 | tokens per gpu per second (tgs): 1765.966 | TFLOPs: 15.75 |
 iteration     1630/   11444 | consumed samples:       208640 | consumed tokens:    427294720 | elapsed time per iteration (ms): 9147.3 | learning rate: 1.806E-04 | global batch size:   128 | lm loss: 3.146908E+00 | moe loss: 1.220409E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.993 | tokens per gpu per second (tgs): 1791.135 | TFLOPs: 15.98 |
 iteration     1640/   11444 | consumed samples:       209920 | consumed tokens:    429916160 | elapsed time per iteration (ms): 9224.6 | learning rate: 1.804E-04 | global batch size:   128 | lm loss: 3.224426E+00 | moe loss: 1.223172E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.876 | tokens per gpu per second (tgs): 1776.125 | TFLOPs: 15.84 |
 iteration     1650/   11444 | consumed samples:       211200 | consumed tokens:    432537600 | elapsed time per iteration (ms): 9158.6 | learning rate: 1.801E-04 | global batch size:   128 | lm loss: 3.184043E+00 | moe loss: 1.220633E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.976 | tokens per gpu per second (tgs): 1788.929 | TFLOPs: 15.96 |
 iteration     1660/   11444 | consumed samples:       212480 | consumed tokens:    435159040 | elapsed time per iteration (ms): 9312.8 | learning rate: 1.799E-04 | global batch size:   128 | lm loss: 3.108186E+00 | moe loss: 1.219890E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.745 | tokens per gpu per second (tgs): 1759.305 | TFLOPs: 15.69 |
 iteration     1670/   11444 | consumed samples:       213760 | consumed tokens:    437780480 | elapsed time per iteration (ms): 9355.1 | learning rate: 1.797E-04 | global batch size:   128 | lm loss: 3.169996E+00 | moe loss: 1.229171E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.682 | tokens per gpu per second (tgs): 1751.345 | TFLOPs: 15.62 |
 iteration     1680/   11444 | consumed samples:       215040 | consumed tokens:    440401920 | elapsed time per iteration (ms): 9091.2 | learning rate: 1.794E-04 | global batch size:   128 | lm loss: 3.180057E+00 | moe loss: 1.225805E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.080 | tokens per gpu per second (tgs): 1802.177 | TFLOPs: 16.07 |
 iteration     1690/   11444 | consumed samples:       216320 | consumed tokens:    443023360 | elapsed time per iteration (ms): 9332.0 | learning rate: 1.792E-04 | global batch size:   128 | lm loss: 3.146726E+00 | moe loss: 1.222463E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.716 | tokens per gpu per second (tgs): 1755.685 | TFLOPs: 15.66 |
 iteration     1700/   11444 | consumed samples:       217600 | consumed tokens:    445644800 | elapsed time per iteration (ms): 9148.0 | learning rate: 1.789E-04 | global batch size:   128 | lm loss: 3.166823E+00 | moe loss: 1.222705E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.992 | tokens per gpu per second (tgs): 1790.999 | TFLOPs: 15.97 |
 iteration     1710/   11444 | consumed samples:       218880 | consumed tokens:    448266240 | elapsed time per iteration (ms): 9495.7 | learning rate: 1.787E-04 | global batch size:   128 | lm loss: 3.173138E+00 | moe loss: 1.223315E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.480 | tokens per gpu per second (tgs): 1725.417 | TFLOPs: 15.39 |
 iteration     1720/   11444 | consumed samples:       220160 | consumed tokens:    450887680 | elapsed time per iteration (ms): 9199.9 | learning rate: 1.785E-04 | global batch size:   128 | lm loss: 3.134188E+00 | moe loss: 1.221948E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.913 | tokens per gpu per second (tgs): 1780.894 | TFLOPs: 15.88 |
 iteration     1730/   11444 | consumed samples:       221440 | consumed tokens:    453509120 | elapsed time per iteration (ms): 9481.3 | learning rate: 1.782E-04 | global batch size:   128 | lm loss: 3.162695E+00 | moe loss: 1.222974E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.500 | tokens per gpu per second (tgs): 1728.031 | TFLOPs: 15.41 |
 iteration     1740/   11444 | consumed samples:       222720 | consumed tokens:    456130560 | elapsed time per iteration (ms): 9233.0 | learning rate: 1.780E-04 | global batch size:   128 | lm loss: 3.142406E+00 | moe loss: 1.218528E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.863 | tokens per gpu per second (tgs): 1774.504 | TFLOPs: 15.83 |
 iteration     1750/   11444 | consumed samples:       224000 | consumed tokens:    458752000 | elapsed time per iteration (ms): 9339.3 | learning rate: 1.777E-04 | global batch size:   128 | lm loss: 3.121606E+00 | moe loss: 1.220503E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.705 | tokens per gpu per second (tgs): 1754.303 | TFLOPs: 15.65 |
 iteration     1760/   11444 | consumed samples:       225280 | consumed tokens:    461373440 | elapsed time per iteration (ms): 9225.0 | learning rate: 1.775E-04 | global batch size:   128 | lm loss: 3.153889E+00 | moe loss: 1.225991E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.875 | tokens per gpu per second (tgs): 1776.053 | TFLOPs: 15.84 |
 iteration     1770/   11444 | consumed samples:       226560 | consumed tokens:    463994880 | elapsed time per iteration (ms): 9006.0 | learning rate: 1.773E-04 | global batch size:   128 | lm loss: 3.120244E+00 | moe loss: 1.221134E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.213 | tokens per gpu per second (tgs): 1819.239 | TFLOPs: 16.23 |
 iteration     1780/   11444 | consumed samples:       227840 | consumed tokens:    466616320 | elapsed time per iteration (ms): 9167.8 | learning rate: 1.770E-04 | global batch size:   128 | lm loss: 3.123079E+00 | moe loss: 1.220237E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.962 | tokens per gpu per second (tgs): 1787.118 | TFLOPs: 15.94 |
 iteration     1790/   11444 | consumed samples:       229120 | consumed tokens:    469237760 | elapsed time per iteration (ms): 9301.5 | learning rate: 1.768E-04 | global batch size:   128 | lm loss: 3.130388E+00 | moe loss: 1.221989E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.761 | tokens per gpu per second (tgs): 1761.439 | TFLOPs: 15.71 |
 iteration     1800/   11444 | consumed samples:       230400 | consumed tokens:    471859200 | elapsed time per iteration (ms): 9328.3 | learning rate: 1.765E-04 | global batch size:   128 | lm loss: 3.114017E+00 | moe loss: 1.222594E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.722 | tokens per gpu per second (tgs): 1756.381 | TFLOPs: 15.67 |
 iteration     1810/   11444 | consumed samples:       231680 | consumed tokens:    474480640 | elapsed time per iteration (ms): 9137.3 | learning rate: 1.763E-04 | global batch size:   128 | lm loss: 3.099165E+00 | moe loss: 1.223562E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.009 | tokens per gpu per second (tgs): 1793.095 | TFLOPs: 15.99 |
 iteration     1820/   11444 | consumed samples:       232960 | consumed tokens:    477102080 | elapsed time per iteration (ms): 9393.0 | learning rate: 1.760E-04 | global batch size:   128 | lm loss: 3.079871E+00 | moe loss: 1.223792E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.627 | tokens per gpu per second (tgs): 1744.286 | TFLOPs: 15.56 |
 iteration     1830/   11444 | consumed samples:       234240 | consumed tokens:    479723520 | elapsed time per iteration (ms): 9308.6 | learning rate: 1.758E-04 | global batch size:   128 | lm loss: 3.108074E+00 | moe loss: 1.218196E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.751 | tokens per gpu per second (tgs): 1760.090 | TFLOPs: 15.70 |
 iteration     1840/   11444 | consumed samples:       235520 | consumed tokens:    482344960 | elapsed time per iteration (ms): 9224.2 | learning rate: 1.755E-04 | global batch size:   128 | lm loss: 3.094815E+00 | moe loss: 1.221688E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.877 | tokens per gpu per second (tgs): 1776.206 | TFLOPs: 15.84 |
 iteration     1850/   11444 | consumed samples:       236800 | consumed tokens:    484966400 | elapsed time per iteration (ms): 9073.2 | learning rate: 1.752E-04 | global batch size:   128 | lm loss: 3.095938E+00 | moe loss: 1.223330E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.108 | tokens per gpu per second (tgs): 1805.761 | TFLOPs: 16.11 |
 iteration     1860/   11444 | consumed samples:       238080 | consumed tokens:    487587840 | elapsed time per iteration (ms): 9118.8 | learning rate: 1.750E-04 | global batch size:   128 | lm loss: 3.092043E+00 | moe loss: 1.221086E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.037 | tokens per gpu per second (tgs): 1796.728 | TFLOPs: 16.03 |
 iteration     1870/   11444 | consumed samples:       239360 | consumed tokens:    490209280 | elapsed time per iteration (ms): 9280.8 | learning rate: 1.747E-04 | global batch size:   128 | lm loss: 3.098150E+00 | moe loss: 1.217670E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.792 | tokens per gpu per second (tgs): 1765.372 | TFLOPs: 15.75 |
 iteration     1880/   11444 | consumed samples:       240640 | consumed tokens:    492830720 | elapsed time per iteration (ms): 9320.6 | learning rate: 1.745E-04 | global batch size:   128 | lm loss: 3.095731E+00 | moe loss: 1.220294E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.733 | tokens per gpu per second (tgs): 1757.817 | TFLOPs: 15.68 |
 iteration     1890/   11444 | consumed samples:       241920 | consumed tokens:    495452160 | elapsed time per iteration (ms): 8930.2 | learning rate: 1.742E-04 | global batch size:   128 | lm loss: 3.048797E+00 | moe loss: 1.219466E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.333 | tokens per gpu per second (tgs): 1834.670 | TFLOPs: 16.36 |
 iteration     1900/   11444 | consumed samples:       243200 | consumed tokens:    498073600 | elapsed time per iteration (ms): 9162.4 | learning rate: 1.740E-04 | global batch size:   128 | lm loss: 3.067516E+00 | moe loss: 1.221132E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.970 | tokens per gpu per second (tgs): 1788.182 | TFLOPs: 15.95 |
 iteration     1910/   11444 | consumed samples:       244480 | consumed tokens:    500695040 | elapsed time per iteration (ms): 9254.0 | learning rate: 1.737E-04 | global batch size:   128 | lm loss: 3.078360E+00 | moe loss: 1.222287E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.832 | tokens per gpu per second (tgs): 1770.472 | TFLOPs: 15.79 |
 iteration     1920/   11444 | consumed samples:       245760 | consumed tokens:    503316480 | elapsed time per iteration (ms): 9077.1 | learning rate: 1.734E-04 | global batch size:   128 | lm loss: 3.081799E+00 | moe loss: 1.219733E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.101 | tokens per gpu per second (tgs): 1804.976 | TFLOPs: 16.10 |
 iteration     1930/   11444 | consumed samples:       247040 | consumed tokens:    505937920 | elapsed time per iteration (ms): 9119.6 | learning rate: 1.732E-04 | global batch size:   128 | lm loss: 3.034859E+00 | moe loss: 1.225377E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.036 | tokens per gpu per second (tgs): 1796.565 | TFLOPs: 16.02 |
 iteration     1940/   11444 | consumed samples:       248320 | consumed tokens:    508559360 | elapsed time per iteration (ms): 9044.0 | learning rate: 1.729E-04 | global batch size:   128 | lm loss: 3.092082E+00 | moe loss: 1.224432E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.153 | tokens per gpu per second (tgs): 1811.580 | TFLOPs: 16.16 |
 iteration     1950/   11444 | consumed samples:       249600 | consumed tokens:    511180800 | elapsed time per iteration (ms): 9437.2 | learning rate: 1.726E-04 | global batch size:   128 | lm loss: 3.011536E+00 | moe loss: 1.219921E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.563 | tokens per gpu per second (tgs): 1736.108 | TFLOPs: 15.48 |
 iteration     1960/   11444 | consumed samples:       250880 | consumed tokens:    513802240 | elapsed time per iteration (ms): 9260.0 | learning rate: 1.724E-04 | global batch size:   128 | lm loss: 3.024987E+00 | moe loss: 1.217706E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.823 | tokens per gpu per second (tgs): 1769.335 | TFLOPs: 15.78 |
 iteration     1970/   11444 | consumed samples:       252160 | consumed tokens:    516423680 | elapsed time per iteration (ms): 9366.6 | learning rate: 1.721E-04 | global batch size:   128 | lm loss: 3.026819E+00 | moe loss: 1.221087E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.666 | tokens per gpu per second (tgs): 1749.200 | TFLOPs: 15.60 |
 iteration     1980/   11444 | consumed samples:       253440 | consumed tokens:    519045120 | elapsed time per iteration (ms): 9357.8 | learning rate: 1.718E-04 | global batch size:   128 | lm loss: 3.068857E+00 | moe loss: 1.219046E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.678 | tokens per gpu per second (tgs): 1750.844 | TFLOPs: 15.62 |
 iteration     1990/   11444 | consumed samples:       254720 | consumed tokens:    521666560 | elapsed time per iteration (ms): 9288.7 | learning rate: 1.716E-04 | global batch size:   128 | lm loss: 3.035331E+00 | moe loss: 1.220211E-01 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.780 | tokens per gpu per second (tgs): 1763.861 | TFLOPs: 15.73 |
 iteration     2000/   11444 | consumed samples:       256000 | consumed tokens:    524288000 | elapsed time per iteration (ms): 9042.4 | learning rate: 1.713E-04 | global batch size:   128 | lm loss: 3.083935E+00 | moe loss: 1.224888E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.156 | tokens per gpu per second (tgs): 1811.916 | TFLOPs: 16.16 |
------------------------------------------------------------------------------------------------
 validation loss at iteration 2000 | lm loss value: 3.009930E+00 | lm loss PPL: 2.028597E+01 | 
------------------------------------------------------------------------------------------------
 iteration     2010/   11444 | consumed samples:       257280 | consumed tokens:    526909440 | elapsed time per iteration (ms): 9851.9 | learning rate: 1.710E-04 | global batch size:   128 | lm loss: 3.062617E+00 | moe loss: 1.220623E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 12.992 | tokens per gpu per second (tgs): 1663.036 | TFLOPs: 14.83 |
 iteration     2020/   11444 | consumed samples:       258560 | consumed tokens:    529530880 | elapsed time per iteration (ms): 9056.8 | learning rate: 1.707E-04 | global batch size:   128 | lm loss: 3.042401E+00 | moe loss: 1.217311E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.133 | tokens per gpu per second (tgs): 1809.032 | TFLOPs: 16.14 |
 iteration     2030/   11444 | consumed samples:       259840 | consumed tokens:    532152320 | elapsed time per iteration (ms): 9184.5 | learning rate: 1.705E-04 | global batch size:   128 | lm loss: 3.079038E+00 | moe loss: 1.220766E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.937 | tokens per gpu per second (tgs): 1783.885 | TFLOPs: 15.91 |
 iteration     2040/   11444 | consumed samples:       261120 | consumed tokens:    534773760 | elapsed time per iteration (ms): 9133.1 | learning rate: 1.702E-04 | global batch size:   128 | lm loss: 3.042535E+00 | moe loss: 1.219724E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.015 | tokens per gpu per second (tgs): 1793.915 | TFLOPs: 16.00 |
 iteration     2050/   11444 | consumed samples:       262400 | consumed tokens:    537395200 | elapsed time per iteration (ms): 9256.8 | learning rate: 1.699E-04 | global batch size:   128 | lm loss: 3.011029E+00 | moe loss: 1.218583E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.828 | tokens per gpu per second (tgs): 1769.941 | TFLOPs: 15.79 |
 iteration     2060/   11444 | consumed samples:       263680 | consumed tokens:    540016640 | elapsed time per iteration (ms): 9057.2 | learning rate: 1.696E-04 | global batch size:   128 | lm loss: 3.006290E+00 | moe loss: 1.223479E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.132 | tokens per gpu per second (tgs): 1808.951 | TFLOPs: 16.13 |
 iteration     2070/   11444 | consumed samples:       264960 | consumed tokens:    542638080 | elapsed time per iteration (ms): 9295.4 | learning rate: 1.694E-04 | global batch size:   128 | lm loss: 3.019585E+00 | moe loss: 1.217521E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.770 | tokens per gpu per second (tgs): 1762.585 | TFLOPs: 15.72 |
 iteration     2080/   11444 | consumed samples:       266240 | consumed tokens:    545259520 | elapsed time per iteration (ms): 9287.9 | learning rate: 1.691E-04 | global batch size:   128 | lm loss: 3.069595E+00 | moe loss: 1.218818E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.781 | tokens per gpu per second (tgs): 1764.007 | TFLOPs: 15.73 |
 iteration     2090/   11444 | consumed samples:       267520 | consumed tokens:    547880960 | elapsed time per iteration (ms): 9166.4 | learning rate: 1.688E-04 | global batch size:   128 | lm loss: 3.017275E+00 | moe loss: 1.220096E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.964 | tokens per gpu per second (tgs): 1787.398 | TFLOPs: 15.94 |
 iteration     2100/   11444 | consumed samples:       268800 | consumed tokens:    550502400 | elapsed time per iteration (ms): 9200.9 | learning rate: 1.685E-04 | global batch size:   128 | lm loss: 2.983148E+00 | moe loss: 1.220250E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.912 | tokens per gpu per second (tgs): 1780.694 | TFLOPs: 15.88 |
 iteration     2110/   11444 | consumed samples:       270080 | consumed tokens:    553123840 | elapsed time per iteration (ms): 9412.7 | learning rate: 1.682E-04 | global batch size:   128 | lm loss: 2.972750E+00 | moe loss: 1.218771E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.599 | tokens per gpu per second (tgs): 1740.632 | TFLOPs: 15.53 |
 iteration     2120/   11444 | consumed samples:       271360 | consumed tokens:    555745280 | elapsed time per iteration (ms): 9407.2 | learning rate: 1.680E-04 | global batch size:   128 | lm loss: 2.972149E+00 | moe loss: 1.218127E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.607 | tokens per gpu per second (tgs): 1741.640 | TFLOPs: 15.53 |
 iteration     2130/   11444 | consumed samples:       272640 | consumed tokens:    558366720 | elapsed time per iteration (ms): 9431.9 | learning rate: 1.677E-04 | global batch size:   128 | lm loss: 3.008774E+00 | moe loss: 1.220751E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.571 | tokens per gpu per second (tgs): 1737.078 | TFLOPs: 15.49 |
 iteration     2140/   11444 | consumed samples:       273920 | consumed tokens:    560988160 | elapsed time per iteration (ms): 9425.8 | learning rate: 1.674E-04 | global batch size:   128 | lm loss: 2.973651E+00 | moe loss: 1.219111E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.580 | tokens per gpu per second (tgs): 1738.212 | TFLOPs: 15.50 |
 iteration     2150/   11444 | consumed samples:       275200 | consumed tokens:    563609600 | elapsed time per iteration (ms): 9442.4 | learning rate: 1.671E-04 | global batch size:   128 | lm loss: 2.977546E+00 | moe loss: 1.218717E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.556 | tokens per gpu per second (tgs): 1735.156 | TFLOPs: 15.48 |
 iteration     2160/   11444 | consumed samples:       276480 | consumed tokens:    566231040 | elapsed time per iteration (ms): 9322.2 | learning rate: 1.668E-04 | global batch size:   128 | lm loss: 3.008404E+00 | moe loss: 1.220874E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.731 | tokens per gpu per second (tgs): 1757.529 | TFLOPs: 15.68 |
 iteration     2170/   11444 | consumed samples:       277760 | consumed tokens:    568852480 | elapsed time per iteration (ms): 9161.1 | learning rate: 1.665E-04 | global batch size:   128 | lm loss: 3.013622E+00 | moe loss: 1.216955E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.972 | tokens per gpu per second (tgs): 1788.433 | TFLOPs: 15.95 |
 iteration     2180/   11444 | consumed samples:       279040 | consumed tokens:    571473920 | elapsed time per iteration (ms): 9687.0 | learning rate: 1.662E-04 | global batch size:   128 | lm loss: 2.994052E+00 | moe loss: 1.219544E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.214 | tokens per gpu per second (tgs): 1691.341 | TFLOPs: 15.09 |
 iteration     2190/   11444 | consumed samples:       280320 | consumed tokens:    574095360 | elapsed time per iteration (ms): 9090.9 | learning rate: 1.659E-04 | global batch size:   128 | lm loss: 3.024021E+00 | moe loss: 1.221532E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.080 | tokens per gpu per second (tgs): 1802.237 | TFLOPs: 16.07 |
 iteration     2200/   11444 | consumed samples:       281600 | consumed tokens:    576716800 | elapsed time per iteration (ms): 9216.3 | learning rate: 1.657E-04 | global batch size:   128 | lm loss: 2.978372E+00 | moe loss: 1.219079E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.888 | tokens per gpu per second (tgs): 1777.724 | TFLOPs: 15.86 |
 iteration     2210/   11444 | consumed samples:       282880 | consumed tokens:    579338240 | elapsed time per iteration (ms): 9274.5 | learning rate: 1.654E-04 | global batch size:   128 | lm loss: 2.985119E+00 | moe loss: 1.220169E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.801 | tokens per gpu per second (tgs): 1766.573 | TFLOPs: 15.76 |
 iteration     2220/   11444 | consumed samples:       284160 | consumed tokens:    581959680 | elapsed time per iteration (ms): 9322.7 | learning rate: 1.651E-04 | global batch size:   128 | lm loss: 3.001653E+00 | moe loss: 1.220693E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.730 | tokens per gpu per second (tgs): 1757.435 | TFLOPs: 15.68 |
 iteration     2230/   11444 | consumed samples:       285440 | consumed tokens:    584581120 | elapsed time per iteration (ms): 9440.5 | learning rate: 1.648E-04 | global batch size:   128 | lm loss: 2.989022E+00 | moe loss: 1.217197E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.559 | tokens per gpu per second (tgs): 1735.503 | TFLOPs: 15.48 |
 iteration     2240/   11444 | consumed samples:       286720 | consumed tokens:    587202560 | elapsed time per iteration (ms): 9247.3 | learning rate: 1.645E-04 | global batch size:   128 | lm loss: 2.932323E+00 | moe loss: 1.215665E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.842 | tokens per gpu per second (tgs): 1771.768 | TFLOPs: 15.80 |
 iteration     2250/   11444 | consumed samples:       288000 | consumed tokens:    589824000 | elapsed time per iteration (ms): 9239.2 | learning rate: 1.642E-04 | global batch size:   128 | lm loss: 2.991695E+00 | moe loss: 1.221005E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.854 | tokens per gpu per second (tgs): 1773.309 | TFLOPs: 15.82 |
 iteration     2260/   11444 | consumed samples:       289280 | consumed tokens:    592445440 | elapsed time per iteration (ms): 9477.2 | learning rate: 1.639E-04 | global batch size:   128 | lm loss: 2.994699E+00 | moe loss: 1.217278E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.506 | tokens per gpu per second (tgs): 1728.784 | TFLOPs: 15.42 |
 iteration     2270/   11444 | consumed samples:       290560 | consumed tokens:    595066880 | elapsed time per iteration (ms): 9333.9 | learning rate: 1.636E-04 | global batch size:   128 | lm loss: 2.992142E+00 | moe loss: 1.221735E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.713 | tokens per gpu per second (tgs): 1755.321 | TFLOPs: 15.66 |
 iteration     2280/   11444 | consumed samples:       291840 | consumed tokens:    597688320 | elapsed time per iteration (ms): 9159.5 | learning rate: 1.633E-04 | global batch size:   128 | lm loss: 2.972791E+00 | moe loss: 1.221098E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.974 | tokens per gpu per second (tgs): 1788.735 | TFLOPs: 15.95 |
 iteration     2290/   11444 | consumed samples:       293120 | consumed tokens:    600309760 | elapsed time per iteration (ms): 9206.7 | learning rate: 1.630E-04 | global batch size:   128 | lm loss: 2.962715E+00 | moe loss: 1.217310E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.903 | tokens per gpu per second (tgs): 1779.580 | TFLOPs: 15.87 |
 iteration     2300/   11444 | consumed samples:       294400 | consumed tokens:    602931200 | elapsed time per iteration (ms): 9229.7 | learning rate: 1.627E-04 | global batch size:   128 | lm loss: 2.952125E+00 | moe loss: 1.218848E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.868 | tokens per gpu per second (tgs): 1775.141 | TFLOPs: 15.83 |
 iteration     2310/   11444 | consumed samples:       295680 | consumed tokens:    605552640 | elapsed time per iteration (ms): 9272.6 | learning rate: 1.624E-04 | global batch size:   128 | lm loss: 2.921208E+00 | moe loss: 1.217505E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.804 | tokens per gpu per second (tgs): 1766.930 | TFLOPs: 15.76 |
 iteration     2320/   11444 | consumed samples:       296960 | consumed tokens:    608174080 | elapsed time per iteration (ms): 9198.7 | learning rate: 1.621E-04 | global batch size:   128 | lm loss: 2.931467E+00 | moe loss: 1.217839E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.915 | tokens per gpu per second (tgs): 1781.117 | TFLOPs: 15.89 |
 iteration     2330/   11444 | consumed samples:       298240 | consumed tokens:    610795520 | elapsed time per iteration (ms): 9327.5 | learning rate: 1.618E-04 | global batch size:   128 | lm loss: 2.985935E+00 | moe loss: 1.216751E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.723 | tokens per gpu per second (tgs): 1756.533 | TFLOPs: 15.67 |
 iteration     2340/   11444 | consumed samples:       299520 | consumed tokens:    613416960 | elapsed time per iteration (ms): 9056.7 | learning rate: 1.615E-04 | global batch size:   128 | lm loss: 2.942482E+00 | moe loss: 1.219247E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.133 | tokens per gpu per second (tgs): 1809.052 | TFLOPs: 16.14 |
 iteration     2350/   11444 | consumed samples:       300800 | consumed tokens:    616038400 | elapsed time per iteration (ms): 9197.0 | learning rate: 1.612E-04 | global batch size:   128 | lm loss: 2.954604E+00 | moe loss: 1.221895E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.918 | tokens per gpu per second (tgs): 1781.450 | TFLOPs: 15.89 |
 iteration     2360/   11444 | consumed samples:       302080 | consumed tokens:    618659840 | elapsed time per iteration (ms): 9264.9 | learning rate: 1.609E-04 | global batch size:   128 | lm loss: 2.984722E+00 | moe loss: 1.216823E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.816 | tokens per gpu per second (tgs): 1768.395 | TFLOPs: 15.77 |
 iteration     2370/   11444 | consumed samples:       303360 | consumed tokens:    621281280 | elapsed time per iteration (ms): 9309.1 | learning rate: 1.606E-04 | global batch size:   128 | lm loss: 2.915535E+00 | moe loss: 1.219340E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.750 | tokens per gpu per second (tgs): 1760.007 | TFLOPs: 15.70 |
 iteration     2380/   11444 | consumed samples:       304640 | consumed tokens:    623902720 | elapsed time per iteration (ms): 9127.8 | learning rate: 1.603E-04 | global batch size:   128 | lm loss: 2.943243E+00 | moe loss: 1.219314E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.023 | tokens per gpu per second (tgs): 1794.957 | TFLOPs: 16.01 |
 iteration     2390/   11444 | consumed samples:       305920 | consumed tokens:    626524160 | elapsed time per iteration (ms): 9494.4 | learning rate: 1.600E-04 | global batch size:   128 | lm loss: 2.969674E+00 | moe loss: 1.218866E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.482 | tokens per gpu per second (tgs): 1725.649 | TFLOPs: 15.39 |
 iteration     2400/   11444 | consumed samples:       307200 | consumed tokens:    629145600 | elapsed time per iteration (ms): 9284.0 | learning rate: 1.596E-04 | global batch size:   128 | lm loss: 2.986582E+00 | moe loss: 1.218053E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.787 | tokens per gpu per second (tgs): 1764.766 | TFLOPs: 15.74 |
 iteration     2410/   11444 | consumed samples:       308480 | consumed tokens:    631767040 | elapsed time per iteration (ms): 9524.8 | learning rate: 1.593E-04 | global batch size:   128 | lm loss: 2.922852E+00 | moe loss: 1.219835E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.439 | tokens per gpu per second (tgs): 1720.140 | TFLOPs: 15.34 |
 iteration     2420/   11444 | consumed samples:       309760 | consumed tokens:    634388480 | elapsed time per iteration (ms): 9319.7 | learning rate: 1.590E-04 | global batch size:   128 | lm loss: 2.904333E+00 | moe loss: 1.220247E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.734 | tokens per gpu per second (tgs): 1758.004 | TFLOPs: 15.68 |
 iteration     2430/   11444 | consumed samples:       311040 | consumed tokens:    637009920 | elapsed time per iteration (ms): 9272.5 | learning rate: 1.587E-04 | global batch size:   128 | lm loss: 2.932408E+00 | moe loss: 1.217713E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.804 | tokens per gpu per second (tgs): 1766.944 | TFLOPs: 15.76 |
 iteration     2440/   11444 | consumed samples:       312320 | consumed tokens:    639631360 | elapsed time per iteration (ms): 9335.2 | learning rate: 1.584E-04 | global batch size:   128 | lm loss: 2.946592E+00 | moe loss: 1.215456E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.712 | tokens per gpu per second (tgs): 1755.074 | TFLOPs: 15.65 |
 iteration     2450/   11444 | consumed samples:       313600 | consumed tokens:    642252800 | elapsed time per iteration (ms): 9286.5 | learning rate: 1.581E-04 | global batch size:   128 | lm loss: 2.914819E+00 | moe loss: 1.217715E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.783 | tokens per gpu per second (tgs): 1764.285 | TFLOPs: 15.74 |
 iteration     2460/   11444 | consumed samples:       314880 | consumed tokens:    644874240 | elapsed time per iteration (ms): 9406.3 | learning rate: 1.578E-04 | global batch size:   128 | lm loss: 2.889522E+00 | moe loss: 1.216602E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.608 | tokens per gpu per second (tgs): 1741.816 | TFLOPs: 15.54 |
 iteration     2470/   11444 | consumed samples:       316160 | consumed tokens:    647495680 | elapsed time per iteration (ms): 9362.2 | learning rate: 1.575E-04 | global batch size:   128 | lm loss: 2.897215E+00 | moe loss: 1.217701E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.672 | tokens per gpu per second (tgs): 1750.019 | TFLOPs: 15.61 |
 iteration     2480/   11444 | consumed samples:       317440 | consumed tokens:    650117120 | elapsed time per iteration (ms): 9277.4 | learning rate: 1.571E-04 | global batch size:   128 | lm loss: 2.900748E+00 | moe loss: 1.216898E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.797 | tokens per gpu per second (tgs): 1766.003 | TFLOPs: 15.75 |
 iteration     2490/   11444 | consumed samples:       318720 | consumed tokens:    652738560 | elapsed time per iteration (ms): 9336.5 | learning rate: 1.568E-04 | global batch size:   128 | lm loss: 2.898592E+00 | moe loss: 1.217810E-01 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.710 | tokens per gpu per second (tgs): 1754.833 | TFLOPs: 15.65 |
 iteration     2500/   11444 | consumed samples:       320000 | consumed tokens:    655360000 | elapsed time per iteration (ms): 9234.2 | learning rate: 1.565E-04 | global batch size:   128 | lm loss: 2.916469E+00 | moe loss: 1.219280E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.861 | tokens per gpu per second (tgs): 1774.266 | TFLOPs: 15.83 |
 iteration     2510/   11444 | consumed samples:       321280 | consumed tokens:    657981440 | elapsed time per iteration (ms): 9382.2 | learning rate: 1.562E-04 | global batch size:   128 | lm loss: 2.933019E+00 | moe loss: 1.218729E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.643 | tokens per gpu per second (tgs): 1746.281 | TFLOPs: 15.58 |
 iteration     2520/   11444 | consumed samples:       322560 | consumed tokens:    660602880 | elapsed time per iteration (ms): 9446.1 | learning rate: 1.559E-04 | global batch size:   128 | lm loss: 2.906992E+00 | moe loss: 1.217586E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.551 | tokens per gpu per second (tgs): 1734.466 | TFLOPs: 15.47 |
 iteration     2530/   11444 | consumed samples:       323840 | consumed tokens:    663224320 | elapsed time per iteration (ms): 9313.5 | learning rate: 1.556E-04 | global batch size:   128 | lm loss: 2.911202E+00 | moe loss: 1.218815E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.744 | tokens per gpu per second (tgs): 1759.175 | TFLOPs: 15.69 |
 iteration     2540/   11444 | consumed samples:       325120 | consumed tokens:    665845760 | elapsed time per iteration (ms): 9474.1 | learning rate: 1.552E-04 | global batch size:   128 | lm loss: 2.910022E+00 | moe loss: 1.217610E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.511 | tokens per gpu per second (tgs): 1729.348 | TFLOPs: 15.42 |
 iteration     2550/   11444 | consumed samples:       326400 | consumed tokens:    668467200 | elapsed time per iteration (ms): 9355.3 | learning rate: 1.549E-04 | global batch size:   128 | lm loss: 2.951372E+00 | moe loss: 1.217736E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.682 | tokens per gpu per second (tgs): 1751.312 | TFLOPs: 15.62 |
 iteration     2560/   11444 | consumed samples:       327680 | consumed tokens:    671088640 | elapsed time per iteration (ms): 8945.6 | learning rate: 1.546E-04 | global batch size:   128 | lm loss: 2.904606E+00 | moe loss: 1.218381E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.309 | tokens per gpu per second (tgs): 1831.510 | TFLOPs: 16.34 |
 iteration     2570/   11444 | consumed samples:       328960 | consumed tokens:    673710080 | elapsed time per iteration (ms): 9327.2 | learning rate: 1.543E-04 | global batch size:   128 | lm loss: 2.903346E+00 | moe loss: 1.218083E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.723 | tokens per gpu per second (tgs): 1756.575 | TFLOPs: 15.67 |
 iteration     2580/   11444 | consumed samples:       330240 | consumed tokens:    676331520 | elapsed time per iteration (ms): 9373.3 | learning rate: 1.539E-04 | global batch size:   128 | lm loss: 2.953005E+00 | moe loss: 1.217143E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.656 | tokens per gpu per second (tgs): 1747.938 | TFLOPs: 15.59 |
 iteration     2590/   11444 | consumed samples:       331520 | consumed tokens:    678952960 | elapsed time per iteration (ms): 9320.4 | learning rate: 1.536E-04 | global batch size:   128 | lm loss: 2.872112E+00 | moe loss: 1.218299E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.733 | tokens per gpu per second (tgs): 1757.857 | TFLOPs: 15.68 |
 iteration     2600/   11444 | consumed samples:       332800 | consumed tokens:    681574400 | elapsed time per iteration (ms): 9170.4 | learning rate: 1.533E-04 | global batch size:   128 | lm loss: 2.886552E+00 | moe loss: 1.218693E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.958 | tokens per gpu per second (tgs): 1786.614 | TFLOPs: 15.94 |
 iteration     2610/   11444 | consumed samples:       334080 | consumed tokens:    684195840 | elapsed time per iteration (ms): 9151.4 | learning rate: 1.530E-04 | global batch size:   128 | lm loss: 2.906919E+00 | moe loss: 1.216917E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.987 | tokens per gpu per second (tgs): 1790.330 | TFLOPs: 15.97 |
 iteration     2620/   11444 | consumed samples:       335360 | consumed tokens:    686817280 | elapsed time per iteration (ms): 9057.2 | learning rate: 1.526E-04 | global batch size:   128 | lm loss: 2.895655E+00 | moe loss: 1.218449E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.132 | tokens per gpu per second (tgs): 1808.948 | TFLOPs: 16.13 |
 iteration     2630/   11444 | consumed samples:       336640 | consumed tokens:    689438720 | elapsed time per iteration (ms): 9525.4 | learning rate: 1.523E-04 | global batch size:   128 | lm loss: 2.944550E+00 | moe loss: 1.215436E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.438 | tokens per gpu per second (tgs): 1720.039 | TFLOPs: 15.34 |
 iteration     2640/   11444 | consumed samples:       337920 | consumed tokens:    692060160 | elapsed time per iteration (ms): 9346.2 | learning rate: 1.520E-04 | global batch size:   128 | lm loss: 2.871353E+00 | moe loss: 1.219153E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.695 | tokens per gpu per second (tgs): 1753.010 | TFLOPs: 15.64 |
 iteration     2650/   11444 | consumed samples:       339200 | consumed tokens:    694681600 | elapsed time per iteration (ms): 9182.8 | learning rate: 1.517E-04 | global batch size:   128 | lm loss: 2.897827E+00 | moe loss: 1.218252E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.939 | tokens per gpu per second (tgs): 1784.206 | TFLOPs: 15.91 |
 iteration     2660/   11444 | consumed samples:       340480 | consumed tokens:    697303040 | elapsed time per iteration (ms): 9523.0 | learning rate: 1.513E-04 | global batch size:   128 | lm loss: 2.867687E+00 | moe loss: 1.216004E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.441 | tokens per gpu per second (tgs): 1720.467 | TFLOPs: 15.35 |
 iteration     2670/   11444 | consumed samples:       341760 | consumed tokens:    699924480 | elapsed time per iteration (ms): 9371.9 | learning rate: 1.510E-04 | global batch size:   128 | lm loss: 2.888676E+00 | moe loss: 1.221732E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.658 | tokens per gpu per second (tgs): 1748.209 | TFLOPs: 15.59 |
 iteration     2680/   11444 | consumed samples:       343040 | consumed tokens:    702545920 | elapsed time per iteration (ms): 9428.2 | learning rate: 1.507E-04 | global batch size:   128 | lm loss: 2.871273E+00 | moe loss: 1.217830E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.576 | tokens per gpu per second (tgs): 1737.772 | TFLOPs: 15.50 |
 iteration     2690/   11444 | consumed samples:       344320 | consumed tokens:    705167360 | elapsed time per iteration (ms): 9312.3 | learning rate: 1.503E-04 | global batch size:   128 | lm loss: 2.910941E+00 | moe loss: 1.220906E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.745 | tokens per gpu per second (tgs): 1759.399 | TFLOPs: 15.69 |
 iteration     2700/   11444 | consumed samples:       345600 | consumed tokens:    707788800 | elapsed time per iteration (ms): 9387.7 | learning rate: 1.500E-04 | global batch size:   128 | lm loss: 2.879546E+00 | moe loss: 1.219103E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.635 | tokens per gpu per second (tgs): 1745.255 | TFLOPs: 15.57 |
 iteration     2710/   11444 | consumed samples:       346880 | consumed tokens:    710410240 | elapsed time per iteration (ms): 9282.7 | learning rate: 1.497E-04 | global batch size:   128 | lm loss: 2.869226E+00 | moe loss: 1.215865E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.789 | tokens per gpu per second (tgs): 1764.998 | TFLOPs: 15.74 |
 iteration     2720/   11444 | consumed samples:       348160 | consumed tokens:    713031680 | elapsed time per iteration (ms): 9265.9 | learning rate: 1.493E-04 | global batch size:   128 | lm loss: 2.859620E+00 | moe loss: 1.215347E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.814 | tokens per gpu per second (tgs): 1768.213 | TFLOPs: 15.77 |
 iteration     2730/   11444 | consumed samples:       349440 | consumed tokens:    715653120 | elapsed time per iteration (ms): 9072.6 | learning rate: 1.490E-04 | global batch size:   128 | lm loss: 2.899405E+00 | moe loss: 1.216688E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.108 | tokens per gpu per second (tgs): 1805.879 | TFLOPs: 16.11 |
 iteration     2740/   11444 | consumed samples:       350720 | consumed tokens:    718274560 | elapsed time per iteration (ms): 9162.7 | learning rate: 1.487E-04 | global batch size:   128 | lm loss: 2.843627E+00 | moe loss: 1.219092E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.970 | tokens per gpu per second (tgs): 1788.118 | TFLOPs: 15.95 |
 iteration     2750/   11444 | consumed samples:       352000 | consumed tokens:    720896000 | elapsed time per iteration (ms): 9135.4 | learning rate: 1.483E-04 | global batch size:   128 | lm loss: 2.851583E+00 | moe loss: 1.218525E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.011 | tokens per gpu per second (tgs): 1793.456 | TFLOPs: 16.00 |
 iteration     2760/   11444 | consumed samples:       353280 | consumed tokens:    723517440 | elapsed time per iteration (ms): 9192.9 | learning rate: 1.480E-04 | global batch size:   128 | lm loss: 2.833890E+00 | moe loss: 1.223746E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.924 | tokens per gpu per second (tgs): 1782.242 | TFLOPs: 15.90 |
 iteration     2770/   11444 | consumed samples:       354560 | consumed tokens:    726138880 | elapsed time per iteration (ms): 9176.3 | learning rate: 1.477E-04 | global batch size:   128 | lm loss: 2.913792E+00 | moe loss: 1.216199E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.949 | tokens per gpu per second (tgs): 1785.477 | TFLOPs: 15.93 |
 iteration     2780/   11444 | consumed samples:       355840 | consumed tokens:    728760320 | elapsed time per iteration (ms): 9266.6 | learning rate: 1.473E-04 | global batch size:   128 | lm loss: 2.850336E+00 | moe loss: 1.219514E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.813 | tokens per gpu per second (tgs): 1768.077 | TFLOPs: 15.77 |
 iteration     2790/   11444 | consumed samples:       357120 | consumed tokens:    731381760 | elapsed time per iteration (ms): 9260.0 | learning rate: 1.470E-04 | global batch size:   128 | lm loss: 2.879969E+00 | moe loss: 1.220009E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.823 | tokens per gpu per second (tgs): 1769.326 | TFLOPs: 15.78 |
 iteration     2800/   11444 | consumed samples:       358400 | consumed tokens:    734003200 | elapsed time per iteration (ms): 9078.0 | learning rate: 1.467E-04 | global batch size:   128 | lm loss: 2.840799E+00 | moe loss: 1.214041E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.100 | tokens per gpu per second (tgs): 1804.798 | TFLOPs: 16.10 |
 iteration     2810/   11444 | consumed samples:       359680 | consumed tokens:    736624640 | elapsed time per iteration (ms): 9038.1 | learning rate: 1.463E-04 | global batch size:   128 | lm loss: 2.848120E+00 | moe loss: 1.218721E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.162 | tokens per gpu per second (tgs): 1812.779 | TFLOPs: 16.17 |
 iteration     2820/   11444 | consumed samples:       360960 | consumed tokens:    739246080 | elapsed time per iteration (ms): 9164.5 | learning rate: 1.460E-04 | global batch size:   128 | lm loss: 2.871325E+00 | moe loss: 1.220319E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.967 | tokens per gpu per second (tgs): 1787.762 | TFLOPs: 15.95 |
 iteration     2830/   11444 | consumed samples:       362240 | consumed tokens:    741867520 | elapsed time per iteration (ms): 9550.3 | learning rate: 1.456E-04 | global batch size:   128 | lm loss: 2.858398E+00 | moe loss: 1.220910E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.403 | tokens per gpu per second (tgs): 1715.544 | TFLOPs: 15.30 |
 iteration     2840/   11444 | consumed samples:       363520 | consumed tokens:    744488960 | elapsed time per iteration (ms): 9355.5 | learning rate: 1.453E-04 | global batch size:   128 | lm loss: 2.848745E+00 | moe loss: 1.218305E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.682 | tokens per gpu per second (tgs): 1751.264 | TFLOPs: 15.62 |
 iteration     2850/   11444 | consumed samples:       364800 | consumed tokens:    747110400 | elapsed time per iteration (ms): 9277.9 | learning rate: 1.450E-04 | global batch size:   128 | lm loss: 2.860528E+00 | moe loss: 1.218614E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.796 | tokens per gpu per second (tgs): 1765.913 | TFLOPs: 15.75 |
 iteration     2860/   11444 | consumed samples:       366080 | consumed tokens:    749731840 | elapsed time per iteration (ms): 9238.9 | learning rate: 1.446E-04 | global batch size:   128 | lm loss: 2.842651E+00 | moe loss: 1.220403E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.855 | tokens per gpu per second (tgs): 1773.378 | TFLOPs: 15.82 |
 iteration     2870/   11444 | consumed samples:       367360 | consumed tokens:    752353280 | elapsed time per iteration (ms): 9008.6 | learning rate: 1.443E-04 | global batch size:   128 | lm loss: 2.866319E+00 | moe loss: 1.218980E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.209 | tokens per gpu per second (tgs): 1818.697 | TFLOPs: 16.22 |
 iteration     2880/   11444 | consumed samples:       368640 | consumed tokens:    754974720 | elapsed time per iteration (ms): 9024.6 | learning rate: 1.439E-04 | global batch size:   128 | lm loss: 2.839544E+00 | moe loss: 1.217356E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.183 | tokens per gpu per second (tgs): 1815.476 | TFLOPs: 16.19 |
 iteration     2890/   11444 | consumed samples:       369920 | consumed tokens:    757596160 | elapsed time per iteration (ms): 9253.9 | learning rate: 1.436E-04 | global batch size:   128 | lm loss: 2.883443E+00 | moe loss: 1.215212E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.832 | tokens per gpu per second (tgs): 1770.496 | TFLOPs: 15.79 |
 iteration     2900/   11444 | consumed samples:       371200 | consumed tokens:    760217600 | elapsed time per iteration (ms): 9359.9 | learning rate: 1.432E-04 | global batch size:   128 | lm loss: 2.825610E+00 | moe loss: 1.217844E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.675 | tokens per gpu per second (tgs): 1750.449 | TFLOPs: 15.61 |
 iteration     2910/   11444 | consumed samples:       372480 | consumed tokens:    762839040 | elapsed time per iteration (ms): 9386.4 | learning rate: 1.429E-04 | global batch size:   128 | lm loss: 2.827321E+00 | moe loss: 1.222113E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.637 | tokens per gpu per second (tgs): 1745.503 | TFLOPs: 15.57 |
 iteration     2920/   11444 | consumed samples:       373760 | consumed tokens:    765460480 | elapsed time per iteration (ms): 9479.7 | learning rate: 1.425E-04 | global batch size:   128 | lm loss: 2.811322E+00 | moe loss: 1.216239E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.503 | tokens per gpu per second (tgs): 1728.322 | TFLOPs: 15.42 |
 iteration     2930/   11444 | consumed samples:       375040 | consumed tokens:    768081920 | elapsed time per iteration (ms): 9407.4 | learning rate: 1.422E-04 | global batch size:   128 | lm loss: 2.834668E+00 | moe loss: 1.219983E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.606 | tokens per gpu per second (tgs): 1741.599 | TFLOPs: 15.53 |
 iteration     2940/   11444 | consumed samples:       376320 | consumed tokens:    770703360 | elapsed time per iteration (ms): 9424.6 | learning rate: 1.419E-04 | global batch size:   128 | lm loss: 2.832223E+00 | moe loss: 1.215639E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.581 | tokens per gpu per second (tgs): 1738.423 | TFLOPs: 15.51 |
 iteration     2950/   11444 | consumed samples:       377600 | consumed tokens:    773324800 | elapsed time per iteration (ms): 9215.3 | learning rate: 1.415E-04 | global batch size:   128 | lm loss: 2.829659E+00 | moe loss: 1.215864E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.890 | tokens per gpu per second (tgs): 1777.917 | TFLOPs: 15.86 |
 iteration     2960/   11444 | consumed samples:       378880 | consumed tokens:    775946240 | elapsed time per iteration (ms): 9258.7 | learning rate: 1.412E-04 | global batch size:   128 | lm loss: 2.819686E+00 | moe loss: 1.220122E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.825 | tokens per gpu per second (tgs): 1769.588 | TFLOPs: 15.78 |
 iteration     2970/   11444 | consumed samples:       380160 | consumed tokens:    778567680 | elapsed time per iteration (ms): 9267.0 | learning rate: 1.408E-04 | global batch size:   128 | lm loss: 2.813376E+00 | moe loss: 1.217365E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.812 | tokens per gpu per second (tgs): 1767.997 | TFLOPs: 15.77 |
 iteration     2980/   11444 | consumed samples:       381440 | consumed tokens:    781189120 | elapsed time per iteration (ms): 9353.5 | learning rate: 1.405E-04 | global batch size:   128 | lm loss: 2.839466E+00 | moe loss: 1.217653E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.685 | tokens per gpu per second (tgs): 1751.653 | TFLOPs: 15.62 |
 iteration     2990/   11444 | consumed samples:       382720 | consumed tokens:    783810560 | elapsed time per iteration (ms): 9121.5 | learning rate: 1.401E-04 | global batch size:   128 | lm loss: 2.819464E+00 | moe loss: 1.217312E-01 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 14.033 | tokens per gpu per second (tgs): 1796.191 | TFLOPs: 16.02 |
 iteration     3000/   11444 | consumed samples:       384000 | consumed tokens:    786432000 | elapsed time per iteration (ms): 9427.3 | learning rate: 1.398E-04 | global batch size:   128 | lm loss: 2.788611E+00 | moe loss: 1.215298E-01 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.578 | tokens per gpu per second (tgs): 1737.938 | TFLOPs: 15.50 |
------------------------------------------------------------------------------------------------
 validation loss at iteration 3000 | lm loss value: 2.817577E+00 | lm loss PPL: 1.673624E+01 | 
------------------------------------------------------------------------------------------------
 iteration     3010/   11444 | consumed samples:       385280 | consumed tokens:    789053440 | elapsed time per iteration (ms): 9976.3 | learning rate: 1.394E-04 | global batch size:   128 | lm loss: 2.810777E+00 | moe loss: 1.218349E-01 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 12.830 | tokens per gpu per second (tgs): 1642.296 | TFLOPs: 14.65 |
 iteration     3020/   11444 | consumed samples:       386560 | consumed tokens:    791674880 | elapsed time per iteration (ms): 9384.1 | learning rate: 1.391E-04 | global batch size:   128 | lm loss: 2.821266E+00 | moe loss: 1.215875E-01 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.640 | tokens per gpu per second (tgs): 1745.924 | TFLOPs: 15.57 |
 iteration     3030/   11444 | consumed samples:       387840 | consumed tokens:    794296320 | elapsed time per iteration (ms): 9368.5 | learning rate: 1.387E-04 | global batch size:   128 | lm loss: 2.810029E+00 | moe loss: 1.218266E-01 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.663 | tokens per gpu per second (tgs): 1748.834 | TFLOPs: 15.60 |
 iteration     3040/   11444 | consumed samples:       389120 | consumed tokens:    796917760 | elapsed time per iteration (ms): 9339.5 | learning rate: 1.384E-04 | global batch size:   128 | lm loss: 2.796849E+00 | moe loss: 1.214901E-01 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.705 | tokens per gpu per second (tgs): 1754.279 | TFLOPs: 15.65 |
 iteration     3050/   11444 | consumed samples:       390400 | consumed tokens:    799539200 | elapsed time per iteration (ms): 9277.2 | learning rate: 1.380E-04 | global batch size:   128 | lm loss: 2.802873E+00 | moe loss: 1.216290E-01 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.797 | tokens per gpu per second (tgs): 1766.049 | TFLOPs: 15.75 |
 iteration     3060/   11444 | consumed samples:       391680 | consumed tokens:    802160640 | elapsed time per iteration (ms): 9173.7 | learning rate: 1.377E-04 | global batch size:   128 | lm loss: 2.863237E+00 | moe loss: 1.218398E-01 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.953 | tokens per gpu per second (tgs): 1785.980 | TFLOPs: 15.93 |
 iteration     3070/   11444 | consumed samples:       392960 | consumed tokens:    804782080 | elapsed time per iteration (ms): 9372.3 | learning rate: 1.373E-04 | global batch size:   128 | lm loss: 2.796858E+00 | moe loss: 1.222116E-01 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.657 | tokens per gpu per second (tgs): 1748.129 | TFLOPs: 15.59 |
 iteration     3080/   11444 | consumed samples:       394240 | consumed tokens:    807403520 | elapsed time per iteration (ms): 9311.4 | learning rate: 1.370E-04 | global batch size:   128 | lm loss: 2.795983E+00 | moe loss: 1.216673E-01 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.747 | tokens per gpu per second (tgs): 1759.567 | TFLOPs: 15.69 |
 iteration     3090/   11444 | consumed samples:       395520 | consumed tokens:    810024960 | elapsed time per iteration (ms): 9343.7 | learning rate: 1.366E-04 | global batch size:   128 | lm loss: 2.795410E+00 | moe loss: 1.216630E-01 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 13.699 | tokens per gpu per second (tgs): 1753.484 | TFLOPs: 15.64 |
Traceback (most recent call last):
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/examples_deepspeed/MoE/../../pretrain_gpt.py", line 350, in <module>
Traceback (most recent call last):
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/examples_deepspeed/MoE/../../pretrain_gpt.py", line 350, in <module>
    pretrain(train_valid_test_datasets_provider,
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/training.py", line 225, in pretrain
    iteration = train(forward_step_func,
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/training.py", line 1181, in train
    pretrain(train_valid_test_datasets_provider,
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/training.py", line 225, in pretrain
    iteration = train(forward_step_func,
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/training.py", line 1181, in train
    train_step(forward_step_func,
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/training.py", line 693, in train_step
    losses_reduced = forward_backward_func(
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/core/pipeline_parallel/schedules.py", line 358, in forward_backward_no_pipelining
    train_step(forward_step_func,
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/training.py", line 693, in train_step
    output_tensor = forward_step(forward_step_func, data_iterator, model, num_microbatches,
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/core/pipeline_parallel/schedules.py", line 199, in forward_step
    output_tensor, loss_func = forward_step_func(data_iterator, model)
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/examples_deepspeed/MoE/../../pretrain_gpt.py", line 276, in forward_step
    losses_reduced = forward_backward_func(
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/core/pipeline_parallel/schedules.py", line 358, in forward_backward_no_pipelining
    output_tensor, other_losses = model(tokens, position_ids, attention_mask,
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    output_tensor = forward_step(forward_step_func, data_iterator, model, num_microbatches,
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/core/pipeline_parallel/schedules.py", line 199, in forward_step
    output_tensor, loss_func = forward_step_func(data_iterator, model)
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/examples_deepspeed/MoE/../../pretrain_gpt.py", line 276, in forward_step
    output_tensor, other_losses = model(tokens, position_ids, attention_mask,
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 1833, in forward
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 1833, in forward
    loss = self.module(*inputs, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    loss = self.module(*inputs, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 139, in forward
    lm_output = post_language_model_processing(
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 62, in post_language_model_processing
    loss = cross_entropy(output.float(), labels)
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/core/tensor_parallel/cross_entropy.py", line 143, in vocab_parallel_cross_entropy
    return forward_call(*args, **kwargs)
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 139, in forward
    lm_output = post_language_model_processing(
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 62, in post_language_model_processing
    loss = cross_entropy(output.float(), labels)
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/core/tensor_parallel/cross_entropy.py", line 143, in vocab_parallel_cross_entropy
Traceback (most recent call last):
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/examples_deepspeed/MoE/../../pretrain_gpt.py", line 350, in <module>
    pretrain(train_valid_test_datasets_provider,
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/training.py", line 225, in pretrain
    iteration = train(forward_step_func,
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/training.py", line 1181, in train
    train_step(forward_step_func,
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/training.py", line 693, in train_step
    losses_reduced = forward_backward_func(
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/core/pipeline_parallel/schedules.py", line 358, in forward_backward_no_pipelining
    output_tensor = forward_step(forward_step_func, data_iterator, model, num_microbatches,
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/core/pipeline_parallel/schedules.py", line 199, in forward_step
    output_tensor, loss_func = forward_step_func(data_iterator, model)
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/examples_deepspeed/MoE/../../pretrain_gpt.py", line 276, in forward_step
    output_tensor, other_losses = model(tokens, position_ids, attention_mask,
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 1833, in forward
    loss = self.module(*inputs, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 139, in forward
    lm_output = post_language_model_processing(
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 62, in post_language_model_processing
    loss = cross_entropy(output.float(), labels)
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/core/tensor_parallel/cross_entropy.py", line 143, in vocab_parallel_cross_entropy
Traceback (most recent call last):
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/examples_deepspeed/MoE/../../pretrain_gpt.py", line 350, in <module>
    pretrain(train_valid_test_datasets_provider,
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/training.py", line 225, in pretrain
    iteration = train(forward_step_func,
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/training.py", line 1181, in train
    train_step(forward_step_func,
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/training.py", line 693, in train_step
    losses_reduced = forward_backward_func(
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/core/pipeline_parallel/schedules.py", line 358, in forward_backward_no_pipelining
    output_tensor = forward_step(forward_step_func, data_iterator, model, num_microbatches,
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/core/pipeline_parallel/schedules.py", line 199, in forward_step
    output_tensor, loss_func = forward_step_func(data_iterator, model)
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/examples_deepspeed/MoE/../../pretrain_gpt.py", line 276, in forward_step
    output_tensor, other_losses = model(tokens, position_ids, attention_mask,
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py", line 1833, in forward
    loss = self.module(*inputs, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 139, in forward
    lm_output = post_language_model_processing(
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/model/gpt_model.py", line 62, in post_language_model_processing
    loss = cross_entropy(output.float(), labels)
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/core/tensor_parallel/cross_entropy.py", line 143, in vocab_parallel_cross_entropy
        return _VocabParallelCrossEntropy.apply(vocab_parallel_logits, target, label_smoothing)    return _VocabParallelCrossEntropy.apply(vocab_parallel_logits, target, label_smoothing)    
return _VocabParallelCrossEntropy.apply(vocab_parallel_logits, target, label_smoothing)
return _VocabParallelCrossEntropy.apply(vocab_parallel_logits, target, label_smoothing)
  File "/usr/local/lib/python3.8/dist-packages/torch/autograd/function.py", line 539, in apply
  File "/usr/local/lib/python3.8/dist-packages/torch/autograd/function.py", line 539, in apply

  File "/usr/local/lib/python3.8/dist-packages/torch/autograd/function.py", line 539, in apply
  File "/usr/local/lib/python3.8/dist-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
      File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/core/tensor_parallel/cross_entropy.py", line 25, in forward
    return super().apply(*args, **kwargs)  # type: ignore[misc]return super().apply(*args, **kwargs)  # type: ignore[misc]    

return super().apply(*args, **kwargs)  # type: ignore[misc]  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/core/tensor_parallel/cross_entropy.py", line 25, in forward
  File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/core/tensor_parallel/cross_entropy.py", line 25, in forward

      File "/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/megatron/core/tensor_parallel/cross_entropy.py", line 25, in forward
vocab_parallel_logits = vocab_parallel_logits - logits_max.unsqueeze(dim=-1)
torch.cuda.    OutOfMemoryError    vocab_parallel_logits = vocab_parallel_logits - logits_max.unsqueeze(dim=-1)    : vocab_parallel_logits = vocab_parallel_logits - logits_max.unsqueeze(dim=-1)
vocab_parallel_logits = vocab_parallel_logits - logits_max.unsqueeze(dim=-1)CUDA out of memory. Tried to allocate 1.54 GiB. GPU 4 has a total capacty of 79.10 GiB of which 1.46 GiB is free. Process 118915 has 77.64 GiB memory in use. Of the allocated memory 73.89 GiB is allocated by PyTorch, and 1.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


torch.cuda.OutOfMemoryErrortorch.cuda: torch.cuda.CUDA out of memory. Tried to allocate 1.54 GiB. GPU 6 has a total capacty of 79.10 GiB of which 1.38 GiB is free. Process 118918 has 77.71 GiB memory in use. Of the allocated memory 73.87 GiB is allocated by PyTorch, and 1.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONFOutOfMemoryError.
: OutOfMemoryErrorCUDA out of memory. Tried to allocate 1.54 GiB. GPU 1 has a total capacty of 79.10 GiB of which 1.07 GiB is free. Process 118912 has 78.03 GiB memory in use. Of the allocated memory 73.87 GiB is allocated by PyTorch, and 2.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF: 
CUDA out of memory. Tried to allocate 1.54 GiB. GPU 3 has a total capacty of 79.10 GiB of which 1.42 GiB is free. Process 118914 has 77.67 GiB memory in use. Of the allocated memory 73.89 GiB is allocated by PyTorch, and 1.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2023-12-28 07:45:12,027] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 34127 closing signal SIGTERM
[2023-12-28 07:45:12,028] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 34129 closing signal SIGTERM
[2023-12-28 07:45:12,028] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 34132 closing signal SIGTERM
[2023-12-28 07:45:12,029] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 34136 closing signal SIGTERM
[2023-12-28 07:45:18,501] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 1 (pid: 34128) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/nlp_group/zhengxue/LLM/Pretrain/Codes/Megatron-DeepSpeed/examples_deepspeed/MoE/../../pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-12-28_07:45:12
  host      : kml-dtmachine-13390-prod
  rank      : 11 (local_rank: 3)
  exitcode  : 1 (pid: 34130)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-12-28_07:45:12
  host      : kml-dtmachine-13390-prod
  rank      : 12 (local_rank: 4)
  exitcode  : 1 (pid: 34131)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-12-28_07:45:12
  host      : kml-dtmachine-13390-prod
  rank      : 14 (local_rank: 6)
  exitcode  : 1 (pid: 34134)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-12-28_07:45:12
  host      : kml-dtmachine-13390-prod
  rank      : 9 (local_rank: 1)
  exitcode  : 1 (pid: 34128)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
